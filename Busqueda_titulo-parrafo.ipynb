{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de texto\n",
    "### Creación de los dataframe y limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "df = pd.read_csv('pericias_medicas.csv', sep=',',  encoding='utf-8')\n",
    "#convierte en string los datos de la columna text\n",
    "df1 = df['text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def general(txt: str, bert=False, nums=True) -> str:\n",
    "    \"\"\"\n",
    "    Elimina caracteres no deseados\n",
    "    Params:\n",
    "        **txt**:texto a ser limpiado de caracteres no desaeados\n",
    "    \"\"\"\n",
    "    if nums:\n",
    "        txt = re.sub(r'\\d+', ' ', txt)\n",
    "    if not bert:\n",
    "        txt = txt.translate(str.maketrans(\n",
    "            'áéíóúýàèìòùÁÉÍÓÚÀÈÌÒÙÝ', 'aeiouyaeiouAEIOUAEIOUY'))\n",
    "        txt = re.sub(r'[^\\w\\s]', '', txt)\n",
    "\n",
    "    txt = txt.replace('\\r', ' ').replace(\"\\v\", ' ').replace(\n",
    "        \"\\t\", ' ').replace(\"\\f\", ' ').replace(\"\\a\", ' ').replace(\"\\b\", ' ')\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de texto\n",
    "# Primera etapa de la limpieza de texto\n",
    "import re, string, unicodedata\n",
    "'''\n",
    "Se hace la eliminacion de texto entre corchetes, acentos, signos de puntuacion (excepto . y :), palabras con numeros.\n",
    "Se eliminan los espacios de sobra\n",
    "Se eliminan \\r, \\t, \\v, \\f, \\a\n",
    "'''\n",
    "def limpiarTexto1(txt: str, bert=False, nums=False) -> str:\n",
    "    \"\"\"\n",
    "    Elimina caracteres no deseados\n",
    "    Params:\n",
    "        **txt**:texto a ser limpiado de caracteres no desaeados\n",
    "    \"\"\"\n",
    "    if nums:\n",
    "        txt = re.sub(r'\\d+', ' ', txt)\n",
    "    if not bert:\n",
    "        txt = txt.translate(str.maketrans(\n",
    "            'áéíóúýàèìòùÁÉÍÓÚÀÈÌÒÙÝ', 'aeiouyaeiouAEIOUAEIOUY'))\n",
    "\n",
    "    '''\n",
    "    Eliminamos caracteres especiales: tabulador horizontal(\\t), tabulador vertical(\\v), \n",
    "    retorno de carro(\\r), avance de pagina(\\f), \n",
    "    caracter de retroceso: Marca el límite de una palabra(\\b), \n",
    "    '''\n",
    "    txt = txt.replace('\\r', ' ').replace(\"\\v\", ' ').replace(\n",
    "        \"\\t\", ' ').replace(\"\\f\", ' ').replace(\"\\a\", ' ').replace(\"\\b\", ' ')\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    return txt\n",
    "df1 = df1.apply(str)\n",
    "df1 = df1.apply(limpiarTexto1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda fase de limpieza\n",
    "# Se eliminan todos los elementos que meten ruido al texto y que no fueron eliminados en la fase de limpieza 1.\n",
    "import re\n",
    "\n",
    "def limpiarTexto2(text):\n",
    "    text = re.sub('^ ',' ',text)\n",
    "    text = re.sub('\\n +\\n','\\n',text)\n",
    "    text = re.sub(' +\\n\\n','\\n',text)\n",
    "    text = re.sub('\\n\\n+','\\n',text)\n",
    "    text = re.sub(' \\n','\\n',text)\n",
    "    text = re.sub('\\d\\n','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('\\u200b\\n','',text)\n",
    "    text = re.sub('\\d{3,100}','',text)\n",
    "    text = re.sub('\\d+-\\d+','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('[nN]º|[nN][. ]º','',text)\n",
    "    text = re.sub('[º<>/]','',text)\n",
    "    text = re.sub('\\d{3,100}','',text)\n",
    "    text = re.sub('[a-zA-z-.]+@[a-zA-Z]+.com','',text)\n",
    "    return text\n",
    "\n",
    "df1 = df1.apply(limpiarTexto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercera fase de limpieza\n",
    "# Eliminamos las lineas que no son de utilidad para el analisis o que van a afectar los resultados del mismo.\n",
    "# Ejemplo de linea eliminada: las lineas que comienzan con \"Se encuentra contestada en.....\"\n",
    "import re\n",
    "\n",
    "def limpiarTexto3(text):\n",
    "    text = re.sub('[a-z1-9.]+[).-] [s|S]e encuentra contestad[a|o] .+[. \\n]','',text)\n",
    "    text = re.sub('[0-9]+[. ]+[yY]a fue contestado.+[.\\n]','',text)\n",
    "    text = re.sub('[fF]oja [1-9].+\\n', '', text)\n",
    "    text = re.sub('[pP]regunta[ 0-9]+[)].+\\n|[rR]espuesta[ 0-9]+[)].+\\n','',text)#elimina oraciones comenzadas en preguta/respuesta.\n",
    "    text = re.sub('V[. ]+[S\\n\\.]+', '', text)\n",
    "    #text = re.sub('[IV]+.[A-Z]{1,3}[\\n.]', '', text)\n",
    "    text = re.sub('[I][.][P][.]','',text)\n",
    "    text = re.sub('[I][.][T][.]','',text)\n",
    "    text = re.sub('[I][.][A][.]','',text)\n",
    "    text = re.sub('[I][.][L][.]','',text)\n",
    "    text = re.sub('[I][.][B][.]','',text)\n",
    "    text = re.sub('[I][.][N][.]','',text)\n",
    "    text = re.sub('[I][.][V][.]','',text)\n",
    "    text = re.sub('[V][.][M][.]','',text)\n",
    "    text = re.sub('[V][.][A][.]','',text)\n",
    "\n",
    "    return text\n",
    "\n",
    "dfLimpio = df1.apply(limpiarTexto3)\n",
    "dfLimpio = dfLimpio.apply(limpiarTexto2)\n",
    "#pprint(dfLimpio[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "stops = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "def remove_stops(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Función que elimina stopwords\n",
    "    Params:\n",
    "        **texto**:texto a ser limpiado de stopwords\n",
    "\n",
    "    \"\"\"\n",
    "    texto = [\n",
    "        i for i in texto.split() if i not in stops\n",
    "    ]\n",
    "    return ' '.join(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_palabras(text):\n",
    "    text=text.lower()\n",
    "    text = [\n",
    "        i for i in text.split() if len(i) > 3\n",
    "    ]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busqueda de titulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Títulos con números romanos y en mayúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca títulos en mayusculas\n",
    "def buscarTitulosMayusculas(text):\n",
    "    # Expresiín regular para encontrar títulos en mayusculas.\n",
    "    tituloMayusculas =re.compile(r'(I{1,3}|IV|V|VI{1,3}|IX|X)[-.) ]+[A-Z -]+[:\\.\\n]') #[1-9]|\n",
    "    titulosMayusculasEncontrados = []\n",
    "\n",
    "    for m in tituloMayusculas.finditer(text):\n",
    "        if len(m.group()) > 8:\n",
    "            titulosMayusculasEncontrados.append(m.group())\n",
    "\n",
    "    return titulosMayusculasEncontrados\n",
    "# titulosMAyuscula: lista que guarda los títulos en mayusculas\n",
    "titulosMayusculas=[]\n",
    "for expediente in dfLimpio:\n",
    "    titulosMayusculas.append(buscarTitulosMayusculas(expediente))\n",
    "\n",
    "dfTitulosMayusculasConStops = pd.DataFrame(titulosMayusculas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de dataframe de solo titulos en mayusculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe para guardar expedientes que solamente tienen titulos en mayusculas\n",
    "#dfTitulosMayusculas = pd.DataFrame(columns=['id', 'expediente'])\n",
    "\n",
    "# Guardo en dfTitulosMayusculas los expedientes y su indice dentro del dataframe limpio (con todos los expedientes)\n",
    "expConTitulosMayusculas = []\n",
    "expSinTitulosEncontrados = []\n",
    "for id,titulo in  enumerate(dfLimpio):\n",
    "    if len(titulosMayusculas[id]) > 0:\n",
    "        expConTitulosMayusculas.append((id,titulo))\n",
    "    else:\n",
    "        expSinTitulosEncontrados.append((id,titulo))\n",
    "\n",
    "\n",
    "dfTitulosMayusculas = pd.DataFrame(expConTitulosMayusculas, columns=['id','expediente'])\n",
    "dfSinTitulosEncontrados = pd.DataFrame(expSinTitulosEncontrados, columns=['id','expediente'])\n",
    "#pprint(dfTitulosMayusculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUEVAS BUSQUEDAS\n",
    "### Títulos con números latinos y en mayúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca títulos en mayusculas\n",
    "def buscarTitulosLatinosMayusculas(text):\n",
    "    # Expresiín regular para encontrar títulos en mayusculas.\n",
    "    tituloMayusculas =re.compile(r'[0-9][.) -]+[A-Z -]+[:\\.\\n]') #[1-9]|\n",
    "    titulosMayusculasEncontrados = []\n",
    "    #i=1\n",
    "    for m in tituloMayusculas.finditer(text):\n",
    "        if len(m.group()) > 8:# and re.findall(str(i),m.group()):\n",
    "            titulosMayusculasEncontrados.append(m.group())\n",
    "            #i=i+1\n",
    "\n",
    "    return titulosMayusculasEncontrados\n",
    "# titulosMAyuscula: lista que guarda los títulos en mayusculas\n",
    "titulosLatinosMayusculas=[]\n",
    "for expediente in dfSinTitulosEncontrados['expediente']:\n",
    "    if len(buscarTitulosLatinosMayusculas(expediente)) > 3:\n",
    "        titulosLatinosMayusculas.append(buscarTitulosLatinosMayusculas(expediente))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulosLatinosMayusculas\n",
    "# eliminar longitudes cortas de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTitulosMayusculas.to_excel('titulos_mayusculas.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expedientes con titulos en mayusculas sobre el total de expedientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de expediente que tienen titulos en mayusculas:        1274\n",
      "Cantidad de expedientes que no tienen titulos en mayusculas:    2532  \n",
      "Total de expedientes: 3806 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Cantidad de expediente que tienen titulos en mayusculas:        {len(dfTitulosMayusculas)}\n",
    "Cantidad de expedientes que no tienen titulos en mayusculas:    {len(dfLimpio) - len(dfTitulosMayusculas)}  \n",
    "Total de expedientes: {len(dfLimpio)} \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'c:\\\\Users\\\\gasto\\\\anaconda3\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creo un grafico de torta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "totalExp = len(dfLimpio)\n",
    "totalExpMayusculas = len(dfTitulosMayusculas)\n",
    "\n",
    "# Creación de grafico de torta de la cantidad de expedientes con títulos en mayúsculas sobre el total de expedientes.\n",
    "cantExp = [totalExp, totalExpMayusculas]\n",
    "nombreTitulos = ['Total de Expedientes', 'Total de Expedientes con Títulos en Mayúsculas']\n",
    "colores = ['#2C4AF1','#2CF168']\n",
    "desfase=(0,0.1)\n",
    "\n",
    "plt.pie(cantExp, labels=nombreTitulos, autopct= '%0.1f %%', colors=colores, explode=desfase) #, explode=desfase\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titulos y ubicacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('II.- HISTORIA CLINICA\\n', 0, 22, 22),\n",
      " ('III.- ESTUDIOS SOLICITADOS\\n', 3860, 3887, 27),\n",
      " ('IV.- PUNTOS PERICIALES\\n', 4309, 4332, 23),\n",
      " ('V.- CONSIDERACIONES Y CONCLUSIONES MEDICO LEGALES\\n', 4647, 4697, 50)]\n"
     ]
    }
   ],
   "source": [
    "# Encontrar la ubicacion del titulo en el documento\n",
    "titulosPosicion=[]\n",
    "\n",
    "for titulo in titulosMayusculas[3803]:\n",
    "    inicioTitulo = dfLimpio[3803].index(titulo)\n",
    "    palabrasPorTitulo = len(titulo)\n",
    "    finalTitulo = inicioTitulo + palabrasPorTitulo\n",
    "    titulosPosicion.append((titulo, inicioTitulo, finalTitulo, palabrasPorTitulo))\n",
    "\n",
    "pprint(titulosPosicion)\n",
    "\n",
    "\n",
    "#anotar parrafos entre titulos.\n",
    "#parrafo = texto[inicio:inicio+1]\n",
    "#mostrar las secciones\n",
    "#estadisiticas de titulos interdocumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1022"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creo una variable que contiene el párrafo de un título en particular\n",
    "parrafoConsideraciones = dfLimpio[3803][4647:]\n",
    "parrafoConsideraciones = general(parrafoConsideraciones)\n",
    "parrafoConsideraciones = remove_stops(parrafoConsideraciones)\n",
    "parrafoConsideraciones = limpiar_palabras(parrafoConsideraciones)\n",
    "#pprint(parrafoConsideraciones)\n",
    "len(parrafoConsideraciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATAFRAME DE UBICACIÓN DE TÍTULOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar la ubicacion del titulo en el documento\n",
    "titulosPosicion1=[]\n",
    "\n",
    "for i in range(len(dfLimpio)):\n",
    "    for titulo in titulosMayusculas[i]:\n",
    "        inicioTitulo = dfLimpio[i].index(titulo)\n",
    "        palabrasPorTitulo = len(titulo)\n",
    "        finalTitulo = inicioTitulo + palabrasPorTitulo\n",
    "        titulosPosicion1.append((i,titulo, inicioTitulo, finalTitulo, palabrasPorTitulo))\n",
    "\n",
    "dfUbicacionTitulos = pd.DataFrame(titulosPosicion1,columns=['id','titulo','inicio','fin','longitud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUbicacionTitulos['titulo'].to_csv('titulosEncontrados.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de la longitud de los parrafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo la longitud de caracteres de parrafos\n",
    "def longitud_parrafos(ubicacion, original):\n",
    "    parrafos=[]\n",
    "    for i in range(len(ubicacion)):\n",
    "        if i < len(ubicacion)-1:\n",
    "            inicio = ubicacion['inicio'][i]\n",
    "            fin = ubicacion['inicio'][i+1]\n",
    "            idDf = ubicacion['id'][i]\n",
    "            if (fin-inicio) > 0:\n",
    "                parrafo = original[idDf][inicio:fin]\n",
    "                parrafo = general(parrafo)\n",
    "                parrafo = remove_stops(parrafo)\n",
    "                parrafo = limpiar_palabras(parrafo)\n",
    "                caracteres = len(parrafo.split())\n",
    "                parrafos.append(caracteres)\n",
    "            else:\n",
    "                parrafo = original[idDf][inicio:]\n",
    "                parrafo = general(parrafo)\n",
    "                parrafo = remove_stops(parrafo)\n",
    "                parrafo = limpiar_palabras(parrafo)\n",
    "                caracteres = len(parrafo.split())\n",
    "                parrafos.append(caracteres)\n",
    "    return parrafos\n",
    "\n",
    "longitudP = longitud_parrafos(dfUbicacionTitulos, dfLimpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUbicacionTitulos['longitud_parrafo'] = pd.DataFrame(longitudP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5775.000000\n",
       "mean      276.017662\n",
       "std       483.944481\n",
       "min         0.000000\n",
       "25%        32.000000\n",
       "50%        92.000000\n",
       "75%       309.000000\n",
       "max      5363.000000\n",
       "Name: longitud_parrafo, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUbicacionTitulos['longitud_parrafo'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una lista de parrafos\n",
    "def extraer_parrafos(ubicacion, original):\n",
    "    parrafos=[]\n",
    "    for i in range(len(ubicacion)):\n",
    "        if i < len(ubicacion)-1:\n",
    "            inicio = ubicacion['fin'][i]\n",
    "            fin = ubicacion['inicio'][i+1]\n",
    "            idDf = ubicacion['id'][i]\n",
    "            if (fin-inicio) > 0:\n",
    "                parrafo = original[idDf][inicio:fin]\n",
    "                caracteres = general(parrafo)\n",
    "                caracteres = remove_stops(caracteres)\n",
    "                caracteres = limpiar_palabras(caracteres)\n",
    "                caracteres = caracteres.split()\n",
    "                parrafos.append(caracteres)\n",
    "            else:\n",
    "                parrafo = original[idDf][inicio:]\n",
    "                caracteres = general(parrafo)\n",
    "                caracteres = remove_stops(caracteres)\n",
    "                caracteres = limpiar_palabras(caracteres)\n",
    "                caracteres = caracteres.split()\n",
    "                parrafos.append(caracteres)\n",
    "    return parrafos\n",
    "\n",
    "parrafos = extraer_parrafos(dfUbicacionTitulos,dfLimpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrafos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNT96878/2016'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['expediente'][165]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREACION DE DOCUMENTO HTML\n",
    "## MUESTRO LOS TITULOS Y PARRAFOS ENCONTRADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe para colocar el salto de linea en formato HTML\n",
    "dfLimpioHTML = dfLimpio.apply(str)\n",
    "def limpiarTextoHTML(text):\n",
    "    text = text.strip().replace('\\n','<br>')\n",
    "    return text\n",
    "\n",
    "dfLimpioHTML = dfLimpioHTML.apply(limpiarTextoHTML)\n",
    "parrafoConsideraciones = limpiarTextoHTML(parrafoConsideraciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'procedimientos': '#cd5c5c',\n",
    "    'cuerpos': '#99ccff',\n",
    "    'afecciones': '#ffa500'\n",
    "}\n",
    "\n",
    "body = f'''\n",
    "        <p>\n",
    "        {dfLimpioHTML[1]}\n",
    "        </p>\n",
    "        <br>\n",
    "        '''\n",
    "body = body.replace(parrafoConsideraciones,f'<span style=\"background-color: #99ccff\">{parrafoConsideraciones}</span>')\n",
    "for titulo in titulosMayusculas[1]:\n",
    "    body = body.replace(titulo,f'<span style=\"background-color: #cd5c5c\">{titulo}</span>')\n",
    "with open('parrafos.html','w', encoding=\"utf-8\") as f:\n",
    "    f.write(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contar las oraciones por parrafo.\n",
    "# contar oraciones por parrafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulosTfIdf = limpiar_palabras(str(titulosMayusculas))\n",
    "titulosTfIdf = remove_stops(titulosTfIdf)\n",
    "titulosTfIdf = re.sub(r'(I{1,3}|IV|V|VI{1,3}|IX|X)[). -]|[^\\w\\s]','',str(titulosMayusculas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulosTfIdf[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulosMayusculasLower = limpiar_palabras(str(titulosMayusculas))\n",
    "titulosMayusculasLower = remove_stops(str(titulosMayusculasLower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulosMayusculasLower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not super pythonic, no, not at all.\n",
    "#use extend so it's a big flat list of vocab\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in titulosTfIdf:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 124979 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "print ('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1274, 1670)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2,\n",
    "                                 use_idf=True, ngram_range=(1,5))# tokenizer=tokenize_and_stem\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(dfTitulosMayusculas['expediente']) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "coun_vect = CountVectorizer()\n",
    "count_matrix = coun_vect.fit_transform(titulosMayusculasLower.split())\n",
    "count_array = count_matrix.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42875111758dffc1ca879dbe67063d4b14d2fb8b4b9c438105dae1201065df52"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
