{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaston411/Mi-Proyecto/blob/brendanahir/Kmean_Lda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BrjQoPjTw9xd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from wordcloud    import WordCloud\n",
        "%matplotlib inline\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from sklearn.metrics import silhouette_samples,silhouette_score\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.preprocessing import Normalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mAwpaifUxHC3"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KGBb-OH-xMgI",
        "outputId": "75fbb5bc-972f-4dba-f8ad-ebab0d669e4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-29 14:19:17.607013: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting es-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.4.0/es_core_news_sm-3.4.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from es-core-news-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.9.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.9.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mruqEC4vxOnP",
        "outputId": "8209b6b9-ca8d-4aeb-cec8-50128006e419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_fI75-SxhEo",
        "outputId": "ab4716e7-74d8-4d2c-d49a-6a31220a5a2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       I-PROEMIO:\\nSr. JUEZ NACIONAL:\\nHORTAS MARIA A...\n",
              "1       II-ANTECEDENTES DE INTERES MEDICO-LEGAL:\\nlas ...\n",
              "2       III-EXAMEN FISICO DEL ACTOR:\\nIII-1 PROSOGRAFI...\n",
              "3       IV-CONSIDERACIONES MEDICO-LEGALES:\\nComenta el...\n",
              "4       VII-CONCLUSIONES.\\n1.\\nLas secuelas en el tobi...\n",
              "                              ...                        \n",
              "4106    V) CONCLUSIONES\\nEn conclusion, la Srta. MARIN...\n",
              "4107    VI) PETITORIO\\nSolicito respetuosamente a  que...\n",
              "4108    IX.- PETITORIO: Conforme lo dicho solicito:\\n1...\n",
              "4109    III.- ESTUDIOS SOLICITADOS\\nA.- Fojas RMN homb...\n",
              "4110    IV.- PUNTOS PERICIALES\\nActora\\n1.- contestado...\n",
              "Name: parrafo, Length: 4111, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/ArchivosCSV/df_parrafosCompletos.csv', sep=',',  encoding='utf-8')\n",
        "#convierte en string los datos de la columna text\n",
        "df1 = df['parrafo'].apply(str)\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "s3rbguTiyBvC",
        "outputId": "6e58848d-21e5-408b-84cb-b86c890100dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                parrafo\n",
              "0     I-PROEMIO:\\nSr. JUEZ NACIONAL:\\nHORTAS MARIA A...\n",
              "1     II-ANTECEDENTES DE INTERES MEDICO-LEGAL:\\nlas ...\n",
              "2     III-EXAMEN FISICO DEL ACTOR:\\nIII-1 PROSOGRAFI...\n",
              "3     IV-CONSIDERACIONES MEDICO-LEGALES:\\nComenta el...\n",
              "4     VII-CONCLUSIONES.\\n1.\\nLas secuelas en el tobi...\n",
              "...                                                 ...\n",
              "4106  V) CONCLUSIONES\\nEn conclusion, la Srta. MARIN...\n",
              "4107  VI) PETITORIO\\nSolicito respetuosamente a  que...\n",
              "4108  IX.- PETITORIO: Conforme lo dicho solicito:\\n1...\n",
              "4109  III.- ESTUDIOS SOLICITADOS\\nA.- Fojas RMN homb...\n",
              "4110  IV.- PUNTOS PERICIALES\\nActora\\n1.- contestado...\n",
              "\n",
              "[4111 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-438b5bea-2b36-4775-9eaa-f007ed7bfa27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parrafo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I-PROEMIO:\\nSr. JUEZ NACIONAL:\\nHORTAS MARIA A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>II-ANTECEDENTES DE INTERES MEDICO-LEGAL:\\nlas ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>III-EXAMEN FISICO DEL ACTOR:\\nIII-1 PROSOGRAFI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IV-CONSIDERACIONES MEDICO-LEGALES:\\nComenta el...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VII-CONCLUSIONES.\\n1.\\nLas secuelas en el tobi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4106</th>\n",
              "      <td>V) CONCLUSIONES\\nEn conclusion, la Srta. MARIN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4107</th>\n",
              "      <td>VI) PETITORIO\\nSolicito respetuosamente a  que...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4108</th>\n",
              "      <td>IX.- PETITORIO: Conforme lo dicho solicito:\\n1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4109</th>\n",
              "      <td>III.- ESTUDIOS SOLICITADOS\\nA.- Fojas RMN homb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4110</th>\n",
              "      <td>IV.- PUNTOS PERICIALES\\nActora\\n1.- contestado...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4111 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-438b5bea-2b36-4775-9eaa-f007ed7bfa27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-438b5bea-2b36-4775-9eaa-f007ed7bfa27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-438b5bea-2b36-4775-9eaa-f007ed7bfa27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dfnr= pd.DataFrame(df1)\n",
        "dfnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN2w3TN8yNo2",
        "outputId": "600d4759-9c60-4700-8f5a-cd4a8852d03a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopws = set(stopwords.words('spanish'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SR7g-lj6yRlm"
      },
      "outputs": [],
      "source": [
        "from nltk import SnowballStemmer\n",
        "stemmer = SnowballStemmer ('spanish')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "adJH4x9IyUS3"
      },
      "outputs": [],
      "source": [
        "nlp= spacy.load('es_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cZE4DjMFyXe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948d212f-317f-4f14-8f84-7a4922eb5788"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'acuerdo',\n",
              " 'adelante',\n",
              " 'ademas',\n",
              " 'además',\n",
              " 'afirmó',\n",
              " 'agregó',\n",
              " 'ahi',\n",
              " 'ahora',\n",
              " 'ahí',\n",
              " 'al',\n",
              " 'algo',\n",
              " 'alguna',\n",
              " 'algunas',\n",
              " 'alguno',\n",
              " 'algunos',\n",
              " 'algún',\n",
              " 'alli',\n",
              " 'allí',\n",
              " 'alrededor',\n",
              " 'ambos',\n",
              " 'ante',\n",
              " 'anterior',\n",
              " 'antes',\n",
              " 'apenas',\n",
              " 'aproximadamente',\n",
              " 'aquel',\n",
              " 'aquella',\n",
              " 'aquellas',\n",
              " 'aquello',\n",
              " 'aquellos',\n",
              " 'aqui',\n",
              " 'aquél',\n",
              " 'aquélla',\n",
              " 'aquéllas',\n",
              " 'aquéllos',\n",
              " 'aquí',\n",
              " 'arriba',\n",
              " 'aseguró',\n",
              " 'asi',\n",
              " 'así',\n",
              " 'atras',\n",
              " 'aun',\n",
              " 'aunque',\n",
              " 'añadió',\n",
              " 'aún',\n",
              " 'bajo',\n",
              " 'bastante',\n",
              " 'bien',\n",
              " 'breve',\n",
              " 'buen',\n",
              " 'buena',\n",
              " 'buenas',\n",
              " 'bueno',\n",
              " 'buenos',\n",
              " 'cada',\n",
              " 'casi',\n",
              " 'cierta',\n",
              " 'ciertas',\n",
              " 'cierto',\n",
              " 'ciertos',\n",
              " 'cinco',\n",
              " 'claro',\n",
              " 'comentó',\n",
              " 'como',\n",
              " 'con',\n",
              " 'conmigo',\n",
              " 'conocer',\n",
              " 'conseguimos',\n",
              " 'conseguir',\n",
              " 'considera',\n",
              " 'consideró',\n",
              " 'consigo',\n",
              " 'consigue',\n",
              " 'consiguen',\n",
              " 'consigues',\n",
              " 'contigo',\n",
              " 'contra',\n",
              " 'creo',\n",
              " 'cual',\n",
              " 'cuales',\n",
              " 'cualquier',\n",
              " 'cuando',\n",
              " 'cuanta',\n",
              " 'cuantas',\n",
              " 'cuanto',\n",
              " 'cuantos',\n",
              " 'cuatro',\n",
              " 'cuenta',\n",
              " 'cuál',\n",
              " 'cuáles',\n",
              " 'cuándo',\n",
              " 'cuánta',\n",
              " 'cuántas',\n",
              " 'cuánto',\n",
              " 'cuántos',\n",
              " 'cómo',\n",
              " 'da',\n",
              " 'dado',\n",
              " 'dan',\n",
              " 'dar',\n",
              " 'de',\n",
              " 'debajo',\n",
              " 'debe',\n",
              " 'deben',\n",
              " 'debido',\n",
              " 'decir',\n",
              " 'dejó',\n",
              " 'del',\n",
              " 'delante',\n",
              " 'demasiado',\n",
              " 'demás',\n",
              " 'dentro',\n",
              " 'deprisa',\n",
              " 'desde',\n",
              " 'despacio',\n",
              " 'despues',\n",
              " 'después',\n",
              " 'detras',\n",
              " 'detrás',\n",
              " 'dia',\n",
              " 'dias',\n",
              " 'dice',\n",
              " 'dicen',\n",
              " 'dicho',\n",
              " 'dieron',\n",
              " 'diez',\n",
              " 'diferente',\n",
              " 'diferentes',\n",
              " 'dijeron',\n",
              " 'dijo',\n",
              " 'dio',\n",
              " 'doce',\n",
              " 'donde',\n",
              " 'dos',\n",
              " 'durante',\n",
              " 'día',\n",
              " 'días',\n",
              " 'dónde',\n",
              " 'e',\n",
              " 'el',\n",
              " 'ella',\n",
              " 'ellas',\n",
              " 'ello',\n",
              " 'ellos',\n",
              " 'embargo',\n",
              " 'en',\n",
              " 'encima',\n",
              " 'encuentra',\n",
              " 'enfrente',\n",
              " 'enseguida',\n",
              " 'entonces',\n",
              " 'entre',\n",
              " 'era',\n",
              " 'eramos',\n",
              " 'eran',\n",
              " 'eras',\n",
              " 'eres',\n",
              " 'es',\n",
              " 'esa',\n",
              " 'esas',\n",
              " 'ese',\n",
              " 'eso',\n",
              " 'esos',\n",
              " 'esta',\n",
              " 'estaba',\n",
              " 'estaban',\n",
              " 'estado',\n",
              " 'estados',\n",
              " 'estais',\n",
              " 'estamos',\n",
              " 'estan',\n",
              " 'estar',\n",
              " 'estará',\n",
              " 'estas',\n",
              " 'este',\n",
              " 'esto',\n",
              " 'estos',\n",
              " 'estoy',\n",
              " 'estuvo',\n",
              " 'está',\n",
              " 'están',\n",
              " 'excepto',\n",
              " 'existe',\n",
              " 'existen',\n",
              " 'explicó',\n",
              " 'expresó',\n",
              " 'fin',\n",
              " 'final',\n",
              " 'fue',\n",
              " 'fuera',\n",
              " 'fueron',\n",
              " 'fui',\n",
              " 'fuimos',\n",
              " 'gran',\n",
              " 'grande',\n",
              " 'grandes',\n",
              " 'ha',\n",
              " 'haber',\n",
              " 'habia',\n",
              " 'habla',\n",
              " 'hablan',\n",
              " 'habrá',\n",
              " 'había',\n",
              " 'habían',\n",
              " 'hace',\n",
              " 'haceis',\n",
              " 'hacemos',\n",
              " 'hacen',\n",
              " 'hacer',\n",
              " 'hacerlo',\n",
              " 'haces',\n",
              " 'hacia',\n",
              " 'haciendo',\n",
              " 'hago',\n",
              " 'han',\n",
              " 'hasta',\n",
              " 'hay',\n",
              " 'haya',\n",
              " 'he',\n",
              " 'hecho',\n",
              " 'hemos',\n",
              " 'hicieron',\n",
              " 'hizo',\n",
              " 'hoy',\n",
              " 'hubo',\n",
              " 'igual',\n",
              " 'incluso',\n",
              " 'indicó',\n",
              " 'informo',\n",
              " 'informó',\n",
              " 'ir',\n",
              " 'junto',\n",
              " 'la',\n",
              " 'lado',\n",
              " 'largo',\n",
              " 'las',\n",
              " 'le',\n",
              " 'les',\n",
              " 'llegó',\n",
              " 'lleva',\n",
              " 'llevar',\n",
              " 'lo',\n",
              " 'los',\n",
              " 'luego',\n",
              " 'mal',\n",
              " 'manera',\n",
              " 'manifestó',\n",
              " 'mas',\n",
              " 'mayor',\n",
              " 'me',\n",
              " 'mediante',\n",
              " 'medio',\n",
              " 'mejor',\n",
              " 'mencionó',\n",
              " 'menos',\n",
              " 'menudo',\n",
              " 'mi',\n",
              " 'mia',\n",
              " 'mias',\n",
              " 'mientras',\n",
              " 'mio',\n",
              " 'mios',\n",
              " 'mis',\n",
              " 'misma',\n",
              " 'mismas',\n",
              " 'mismo',\n",
              " 'mismos',\n",
              " 'modo',\n",
              " 'mucha',\n",
              " 'muchas',\n",
              " 'mucho',\n",
              " 'muchos',\n",
              " 'muy',\n",
              " 'más',\n",
              " 'mí',\n",
              " 'mía',\n",
              " 'mías',\n",
              " 'mío',\n",
              " 'míos',\n",
              " 'nada',\n",
              " 'nadie',\n",
              " 'ni',\n",
              " 'ninguna',\n",
              " 'ningunas',\n",
              " 'ninguno',\n",
              " 'ningunos',\n",
              " 'ningún',\n",
              " 'no',\n",
              " 'nos',\n",
              " 'nosotras',\n",
              " 'nosotros',\n",
              " 'nuestra',\n",
              " 'nuestras',\n",
              " 'nuestro',\n",
              " 'nuestros',\n",
              " 'nueva',\n",
              " 'nuevas',\n",
              " 'nueve',\n",
              " 'nuevo',\n",
              " 'nuevos',\n",
              " 'nunca',\n",
              " 'o',\n",
              " 'ocho',\n",
              " 'once',\n",
              " 'os',\n",
              " 'otra',\n",
              " 'otras',\n",
              " 'otro',\n",
              " 'otros',\n",
              " 'para',\n",
              " 'parece',\n",
              " 'parte',\n",
              " 'partir',\n",
              " 'pasada',\n",
              " 'pasado',\n",
              " 'paìs',\n",
              " 'peor',\n",
              " 'pero',\n",
              " 'pesar',\n",
              " 'poca',\n",
              " 'pocas',\n",
              " 'poco',\n",
              " 'pocos',\n",
              " 'podeis',\n",
              " 'podemos',\n",
              " 'poder',\n",
              " 'podria',\n",
              " 'podriais',\n",
              " 'podriamos',\n",
              " 'podrian',\n",
              " 'podrias',\n",
              " 'podrá',\n",
              " 'podrán',\n",
              " 'podría',\n",
              " 'podrían',\n",
              " 'poner',\n",
              " 'por',\n",
              " 'porque',\n",
              " 'posible',\n",
              " 'primer',\n",
              " 'primera',\n",
              " 'primero',\n",
              " 'primeros',\n",
              " 'pronto',\n",
              " 'propia',\n",
              " 'propias',\n",
              " 'propio',\n",
              " 'propios',\n",
              " 'proximo',\n",
              " 'próximo',\n",
              " 'próximos',\n",
              " 'pudo',\n",
              " 'pueda',\n",
              " 'puede',\n",
              " 'pueden',\n",
              " 'puedo',\n",
              " 'pues',\n",
              " 'qeu',\n",
              " 'que',\n",
              " 'quedó',\n",
              " 'queremos',\n",
              " 'quien',\n",
              " 'quienes',\n",
              " 'quiere',\n",
              " 'quiza',\n",
              " 'quizas',\n",
              " 'quizá',\n",
              " 'quizás',\n",
              " 'quién',\n",
              " 'quiénes',\n",
              " 'qué',\n",
              " 'realizado',\n",
              " 'realizar',\n",
              " 'realizó',\n",
              " 'repente',\n",
              " 'respecto',\n",
              " 'sabe',\n",
              " 'sabeis',\n",
              " 'sabemos',\n",
              " 'saben',\n",
              " 'saber',\n",
              " 'sabes',\n",
              " 'salvo',\n",
              " 'se',\n",
              " 'sea',\n",
              " 'sean',\n",
              " 'segun',\n",
              " 'segunda',\n",
              " 'segundo',\n",
              " 'según',\n",
              " 'seis',\n",
              " 'ser',\n",
              " 'sera',\n",
              " 'será',\n",
              " 'serán',\n",
              " 'sería',\n",
              " 'señaló',\n",
              " 'si',\n",
              " 'sido',\n",
              " 'siempre',\n",
              " 'siendo',\n",
              " 'siete',\n",
              " 'sigue',\n",
              " 'siguiente',\n",
              " 'sin',\n",
              " 'sino',\n",
              " 'sobre',\n",
              " 'sois',\n",
              " 'sola',\n",
              " 'solamente',\n",
              " 'solas',\n",
              " 'solo',\n",
              " 'solos',\n",
              " 'somos',\n",
              " 'son',\n",
              " 'soy',\n",
              " 'su',\n",
              " 'supuesto',\n",
              " 'sus',\n",
              " 'suya',\n",
              " 'suyas',\n",
              " 'suyo',\n",
              " 'suyos',\n",
              " 'sé',\n",
              " 'sí',\n",
              " 'sólo',\n",
              " 'tal',\n",
              " 'tambien',\n",
              " 'también',\n",
              " 'tampoco',\n",
              " 'tan',\n",
              " 'tanto',\n",
              " 'tarde',\n",
              " 'te',\n",
              " 'temprano',\n",
              " 'tendrá',\n",
              " 'tendrán',\n",
              " 'teneis',\n",
              " 'tenemos',\n",
              " 'tener',\n",
              " 'tenga',\n",
              " 'tengo',\n",
              " 'tenido',\n",
              " 'tenía',\n",
              " 'tercera',\n",
              " 'tercero',\n",
              " 'ti',\n",
              " 'tiene',\n",
              " 'tienen',\n",
              " 'toda',\n",
              " 'todas',\n",
              " 'todavia',\n",
              " 'todavía',\n",
              " 'todo',\n",
              " 'todos',\n",
              " 'total',\n",
              " 'tras',\n",
              " 'trata',\n",
              " 'través',\n",
              " 'tres',\n",
              " 'tu',\n",
              " 'tus',\n",
              " 'tuvo',\n",
              " 'tuya',\n",
              " 'tuyas',\n",
              " 'tuyo',\n",
              " 'tuyos',\n",
              " 'tú',\n",
              " 'u',\n",
              " 'ultimo',\n",
              " 'un',\n",
              " 'una',\n",
              " 'unas',\n",
              " 'uno',\n",
              " 'unos',\n",
              " 'usa',\n",
              " 'usais',\n",
              " 'usamos',\n",
              " 'usan',\n",
              " 'usar',\n",
              " 'usas',\n",
              " 'uso',\n",
              " 'usted',\n",
              " 'ustedes',\n",
              " 'va',\n",
              " 'vais',\n",
              " 'vamos',\n",
              " 'van',\n",
              " 'varias',\n",
              " 'varios',\n",
              " 'vaya',\n",
              " 'veces',\n",
              " 'ver',\n",
              " 'verdad',\n",
              " 'verdadera',\n",
              " 'verdadero',\n",
              " 'vez',\n",
              " 'vosotras',\n",
              " 'vosotros',\n",
              " 'voy',\n",
              " 'vuestra',\n",
              " 'vuestras',\n",
              " 'vuestro',\n",
              " 'vuestros',\n",
              " 'y',\n",
              " 'ya',\n",
              " 'yo',\n",
              " 'él',\n",
              " 'ésa',\n",
              " 'ésas',\n",
              " 'ése',\n",
              " 'ésos',\n",
              " 'ésta',\n",
              " 'éstas',\n",
              " 'éste',\n",
              " 'éstos',\n",
              " 'última',\n",
              " 'últimas',\n",
              " 'último',\n",
              " 'últimos'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "stop_ws= nlp.Defaults.stop_words\n",
        "stop_ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qfQ-Lc29ODvF"
      },
      "outputs": [],
      "source": [
        "def limpiar_palabras(text: str) -> str:\n",
        "    '''\n",
        "    Limpiar palabras en títulos. Solamente deja palabras y espacios en blanco.\n",
        "    Params:\n",
        "        **text**:texto a ser limpiado de palabras no desaeadas\n",
        "    '''\n",
        "    text = re.sub(r'(I{1,3}|IV|V|VI{1,4}|IX|X)[). -]|[^\\w\\s]',' ',text)\n",
        "    text = text.lower().replace('á','a').replace('é','e').replace('í','i').replace('ó','o').replace('ú','u') # removemos minúsculas y tildes\n",
        "    text = re.sub('[^a-zA-Z]',' ', text) #removemos caracteres especiales y numeros.\n",
        "\n",
        "    text = [word for word in text.split(' ') if word not in stop_ws] #removemos stopwords\n",
        "    text = ' '.join(text)\n",
        "    text = [\n",
        "        i for i in text.split() if len(i) > 3\n",
        "    ]\n",
        "    return ' '.join(text)\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "76KwEXVnOJR_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "560acab4-72eb-463f-f9cb-226d39860f77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                parrafo  \\\n",
              "0     I-PROEMIO:\\nSr. JUEZ NACIONAL:\\nHORTAS MARIA A...   \n",
              "1     II-ANTECEDENTES DE INTERES MEDICO-LEGAL:\\nlas ...   \n",
              "2     III-EXAMEN FISICO DEL ACTOR:\\nIII-1 PROSOGRAFI...   \n",
              "3     IV-CONSIDERACIONES MEDICO-LEGALES:\\nComenta el...   \n",
              "4     VII-CONCLUSIONES.\\n1.\\nLas secuelas en el tobi...   \n",
              "...                                                 ...   \n",
              "4106  V) CONCLUSIONES\\nEn conclusion, la Srta. MARIN...   \n",
              "4107  VI) PETITORIO\\nSolicito respetuosamente a  que...   \n",
              "4108  IX.- PETITORIO: Conforme lo dicho solicito:\\n1...   \n",
              "4109  III.- ESTUDIOS SOLICITADOS\\nA.- Fojas RMN homb...   \n",
              "4110  IV.- PUNTOS PERICIALES\\nActora\\n1.- contestado...   \n",
              "\n",
              "                                         seccion_limpia  \n",
              "0     proemio juez nacional hortas maria andrea peri...  \n",
              "1     antecedentes interes medico legal encontraba c...  \n",
              "2     examen fisico actor prosografia presenta exame...  \n",
              "3     consideraciones medico legales comenta boiero ...  \n",
              "4     conclusiones secuelas tobillo izquierdo presen...  \n",
              "...                                                 ...  \n",
              "4106  conclusiones conclusion srta marina luisa aval...  \n",
              "4107  petitorio solicito respetuosamente presentado ...  \n",
              "4108  petitorio conforme solicito presentada pericia...  \n",
              "4109  estudios solicitados fojas hombros derecho cif...  \n",
              "4110  puntos periciales actora contestado contestado...  \n",
              "\n",
              "[4111 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e69453c5-856a-4669-939b-5a5546caefa3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parrafo</th>\n",
              "      <th>seccion_limpia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I-PROEMIO:\\nSr. JUEZ NACIONAL:\\nHORTAS MARIA A...</td>\n",
              "      <td>proemio juez nacional hortas maria andrea peri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>II-ANTECEDENTES DE INTERES MEDICO-LEGAL:\\nlas ...</td>\n",
              "      <td>antecedentes interes medico legal encontraba c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>III-EXAMEN FISICO DEL ACTOR:\\nIII-1 PROSOGRAFI...</td>\n",
              "      <td>examen fisico actor prosografia presenta exame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IV-CONSIDERACIONES MEDICO-LEGALES:\\nComenta el...</td>\n",
              "      <td>consideraciones medico legales comenta boiero ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VII-CONCLUSIONES.\\n1.\\nLas secuelas en el tobi...</td>\n",
              "      <td>conclusiones secuelas tobillo izquierdo presen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4106</th>\n",
              "      <td>V) CONCLUSIONES\\nEn conclusion, la Srta. MARIN...</td>\n",
              "      <td>conclusiones conclusion srta marina luisa aval...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4107</th>\n",
              "      <td>VI) PETITORIO\\nSolicito respetuosamente a  que...</td>\n",
              "      <td>petitorio solicito respetuosamente presentado ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4108</th>\n",
              "      <td>IX.- PETITORIO: Conforme lo dicho solicito:\\n1...</td>\n",
              "      <td>petitorio conforme solicito presentada pericia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4109</th>\n",
              "      <td>III.- ESTUDIOS SOLICITADOS\\nA.- Fojas RMN homb...</td>\n",
              "      <td>estudios solicitados fojas hombros derecho cif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4110</th>\n",
              "      <td>IV.- PUNTOS PERICIALES\\nActora\\n1.- contestado...</td>\n",
              "      <td>puntos periciales actora contestado contestado...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4111 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e69453c5-856a-4669-939b-5a5546caefa3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e69453c5-856a-4669-939b-5a5546caefa3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e69453c5-856a-4669-939b-5a5546caefa3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "dfnr['seccion_limpia']= dfnr.parrafo.apply(limpiar_palabras)\n",
        "dfnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RtSrk_ukyybH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f12e89a-68d7-438d-a484-3b0e0df63cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proemio juez nacional hortas maria andrea perito medico oficio siguientes autos domicilio constituido calle austria piso dpto capital domicilio electronico mashortas cumplimiento dispuesto referente presentes autos examinado boiero franco ivan tomaron momento examen clinico actual consideraron capacidad generica particular puntos pericia solicitados partes\n",
            "Cantidad de palabras:  358\n"
          ]
        }
      ],
      "source": [
        "print(dfnr.seccion_limpia[0])\n",
        "print('Cantidad de palabras: ',(len(dfnr.seccion_limpia[0])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text= 'Hola como estas che'\n",
        "\n",
        "result = len(text.split())\n",
        "result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAL8mKMdUMjd",
        "outputId": "b8551f2c-119f-42c8-e634-0c82f8977e78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(longitudPalabras)\n",
        "plt.title('Distribución de la longitud de palabras')\n",
        "\n",
        "sns.despine();\n"
      ],
      "metadata": {
        "id": "8o_T5R6Z7PbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j0E4e4Fy5BO"
      },
      "outputs": [],
      "source": [
        "!pip install spacy==2.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SZWNx2aCzBdU"
      },
      "outputs": [],
      "source": [
        "from spacy.lemmatizer import Lemmatizer\n",
        "from spacy.lookups import Lookups\n",
        "def lematize(tok):\n",
        "  lookups = Lookups()\n",
        "  lookups.add_table(\"lemma_rules\", {\"noun\": [[\"s\", \"\"]]})\n",
        "  lemmatizer = Lemmatizer(lookups)\n",
        "\n",
        "  if tok.pos_== 'VERB':\n",
        "    tok= tok.lemma_\n",
        "  elif tok.pos_=='NOUN':\n",
        "    tok = lemmatizer(tok.text, tok.pos_)[0]\n",
        "  else:\n",
        "    tok\n",
        "  return tok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IyKQu-0czFZH"
      },
      "outputs": [],
      "source": [
        "lemm = []\n",
        "for sent in dfnr.seccion_limpia:\n",
        "    tokens = nlp(sent)\n",
        "    lem= [lematize(tok)for tok in tokens]\n",
        "    lem = ' '.join(tok.text for tok in tokens)\n",
        "    lemm.append(lem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uesdRHYCQgWj"
      },
      "outputs": [],
      "source": [
        "#Lista de todas las secciones\n",
        "lemm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cuenta la cantidad de palabras por sección y agrega esa columna \"palabra\" al dfnr\n",
        "\n",
        "longitudPalabras = []\n",
        "for palabra in lemm:\n",
        "  longPalabras= len(palabra.split())\n",
        "\n",
        "  longitudPalabras.append((longPalabras))\n",
        "\n",
        "dfnr['palabras']= longitudPalabras\n",
        "dfnr.head(30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "fkvvPpkNbmrK",
        "outputId": "721354ab-2663-4383-f99b-36bd692f8fe0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              parrafo  \\\n",
              "0   I-PROEMIO:\\nSr. JUEZ NACIONAL:\\nHORTAS MARIA A...   \n",
              "1   II-ANTECEDENTES DE INTERES MEDICO-LEGAL:\\nlas ...   \n",
              "2   III-EXAMEN FISICO DEL ACTOR:\\nIII-1 PROSOGRAFI...   \n",
              "3   IV-CONSIDERACIONES MEDICO-LEGALES:\\nComenta el...   \n",
              "4   VII-CONCLUSIONES.\\n1.\\nLas secuelas en el tobi...   \n",
              "5   VII-INCAPACIDAD: el actor por las lesiones suf...   \n",
              "6   VIII CONTESTACION DE LOS PUNTOS DE PERICIA:\\nV...   \n",
              "7   IX-PETITORIO:\\nHabiendo finalizado el trabajo ...   \n",
              "8   II). PREAMBULO.\\nSegun autos (texto de la dema...   \n",
              "9   III). ANTECEDENTES DE INTERES MEDICO PRESENTE ...   \n",
              "10  IV) EXAMEN DEL PERITO DE OFICIO.\\n1º). FECHA Y...   \n",
              "11  V) CONSIDERACIONES MEDICAS:\\nV1) Corroboracion...   \n",
              "12  VII) CONTESTACION DE PUNTOS PERICIALES.\\n A fs...   \n",
              "13  VIII) BIBLIOGRAFIA.\\n1) Neer CS, Impingement l...   \n",
              "14  VII) CONCLUSIONES:\\nDe la evaluacion de los an...   \n",
              "15  IX). PETITORIO.\\nHabiendo finalizado el trabaj...   \n",
              "16  IV.- PUNTOS PERICIALES\\nActora medica-\\n1.- co...   \n",
              "17  III.- ESTUDIOS SOLICITADOS\\n: patologico en am...   \n",
              "18  V.- CONSIDERACIONES Y CONCLUSIONES MEDICO LEGA...   \n",
              "19  I- PROEMIO\\n SEÑOR JUEZ:\\n Jose Dario Chemaya,...   \n",
              "20  III- EVALUACION CLINICA: Fecha: Video llamada ...   \n",
              "21  V- INCAPACIDAD\\nA la fecha del examen medico l...   \n",
              "22  VI- CONSIDERACIONES MEDICO LEGALES\\nSi bien la...   \n",
              "23  VII- CONCLUSION:\\n- Cuadro fisico: Lumbalgia p...   \n",
              "24  VIII- BIBLIOGRAFIA CONSULTADA:\\n-Tabla de Eval...   \n",
              "25  IX- PETITORIO\\nHabiendo finalizado el trabajo ...   \n",
              "26  I.- DATOS PERSONALES\\nNombre y apellido: Espin...   \n",
              "27  II.- MOTIVO DE RECLAMO Y DATOS LABORALES\\nTipo...   \n",
              "28  III.- ANTECEDENTES DE LOS HECHOS EN LITIS\\nEl ...   \n",
              "29  IV.-ANTECEDENTES MEDICOS\\n1.- Antecedentes Her...   \n",
              "\n",
              "                                       seccion_limpia  palabras  \n",
              "0   proemio juez nacional hortas maria andrea peri...        43  \n",
              "1   antecedentes interes medico legal encontraba c...        96  \n",
              "2   examen fisico actor prosografia presenta exame...       539  \n",
              "3   consideraciones medico legales comenta boiero ...       708  \n",
              "4   conclusiones secuelas tobillo izquierdo presen...       115  \n",
              "5   incapacidad actor lesiones sufridas presenta i...        23  \n",
              "6   contestacion puntos pericia actora contestado ...         9  \n",
              "7   petitorio habiendo finalizado trabajo endado r...        45  \n",
              "8   preambulo autos texto demanda conforme manifes...       185  \n",
              "9   antecedentes interes medico presente autos act...       129  \n",
              "10  examen perito oficio fecha lugar evaluacion pr...      2145  \n",
              "11  consideraciones medicas corroboracion diagnost...       797  \n",
              "12  contestacion puntos periciales actora letra it...        93  \n",
              "13  bibliografia neer impingement lesions clin ort...        69  \n",
              "14  conclusiones evaluacion antecedentes obrantes ...        64  \n",
              "15  petitorio habiendo finalizado trabajo endado r...       109  \n",
              "16  puntos periciales actora medica contestado con...         8  \n",
              "17  estudios solicitados patologico ojos contestad...        19  \n",
              "18  consideraciones conclusiones medico legales ac...        95  \n",
              "19  proemio juez jose dario chemaya medico especia...       204  \n",
              "20  evaluacion clinica fecha video llamada presenc...      1216  \n",
              "21  incapacidad fecha examen medico legal estima j...       181  \n",
              "22  consideraciones medico legales determinacion r...        60  \n",
              "23  conclusion cuadro fisico lumbalgia postraumati...        23  \n",
              "24  bibliografia consultada tabla evaluacion incap...        76  \n",
              "25  petitorio habiendo finalizado trabajo endado r...        62  \n",
              "26  datos personales nombre apellido espinosa carl...        40  \n",
              "27  motivo reclamo datos laborales tipo reclamo ac...        18  \n",
              "28  antecedentes hechos litis actor refiere encont...        84  \n",
              "29  antecedentes medicos antecedentes heredo famil...        31  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2672af9a-3c9d-48ac-b678-ec47adf1fee7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parrafo</th>\n",
              "      <th>seccion_limpia</th>\n",
              "      <th>palabras</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I-PROEMIO:\\nSr. JUEZ NACIONAL:\\nHORTAS MARIA A...</td>\n",
              "      <td>proemio juez nacional hortas maria andrea peri...</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>II-ANTECEDENTES DE INTERES MEDICO-LEGAL:\\nlas ...</td>\n",
              "      <td>antecedentes interes medico legal encontraba c...</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>III-EXAMEN FISICO DEL ACTOR:\\nIII-1 PROSOGRAFI...</td>\n",
              "      <td>examen fisico actor prosografia presenta exame...</td>\n",
              "      <td>539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IV-CONSIDERACIONES MEDICO-LEGALES:\\nComenta el...</td>\n",
              "      <td>consideraciones medico legales comenta boiero ...</td>\n",
              "      <td>708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VII-CONCLUSIONES.\\n1.\\nLas secuelas en el tobi...</td>\n",
              "      <td>conclusiones secuelas tobillo izquierdo presen...</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>VII-INCAPACIDAD: el actor por las lesiones suf...</td>\n",
              "      <td>incapacidad actor lesiones sufridas presenta i...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>VIII CONTESTACION DE LOS PUNTOS DE PERICIA:\\nV...</td>\n",
              "      <td>contestacion puntos pericia actora contestado ...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>IX-PETITORIO:\\nHabiendo finalizado el trabajo ...</td>\n",
              "      <td>petitorio habiendo finalizado trabajo endado r...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>II). PREAMBULO.\\nSegun autos (texto de la dema...</td>\n",
              "      <td>preambulo autos texto demanda conforme manifes...</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>III). ANTECEDENTES DE INTERES MEDICO PRESENTE ...</td>\n",
              "      <td>antecedentes interes medico presente autos act...</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>IV) EXAMEN DEL PERITO DE OFICIO.\\n1º). FECHA Y...</td>\n",
              "      <td>examen perito oficio fecha lugar evaluacion pr...</td>\n",
              "      <td>2145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>V) CONSIDERACIONES MEDICAS:\\nV1) Corroboracion...</td>\n",
              "      <td>consideraciones medicas corroboracion diagnost...</td>\n",
              "      <td>797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>VII) CONTESTACION DE PUNTOS PERICIALES.\\n A fs...</td>\n",
              "      <td>contestacion puntos periciales actora letra it...</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>VIII) BIBLIOGRAFIA.\\n1) Neer CS, Impingement l...</td>\n",
              "      <td>bibliografia neer impingement lesions clin ort...</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>VII) CONCLUSIONES:\\nDe la evaluacion de los an...</td>\n",
              "      <td>conclusiones evaluacion antecedentes obrantes ...</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>IX). PETITORIO.\\nHabiendo finalizado el trabaj...</td>\n",
              "      <td>petitorio habiendo finalizado trabajo endado r...</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>IV.- PUNTOS PERICIALES\\nActora medica-\\n1.- co...</td>\n",
              "      <td>puntos periciales actora medica contestado con...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>III.- ESTUDIOS SOLICITADOS\\n: patologico en am...</td>\n",
              "      <td>estudios solicitados patologico ojos contestad...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>V.- CONSIDERACIONES Y CONCLUSIONES MEDICO LEGA...</td>\n",
              "      <td>consideraciones conclusiones medico legales ac...</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I- PROEMIO\\n SEÑOR JUEZ:\\n Jose Dario Chemaya,...</td>\n",
              "      <td>proemio juez jose dario chemaya medico especia...</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>III- EVALUACION CLINICA: Fecha: Video llamada ...</td>\n",
              "      <td>evaluacion clinica fecha video llamada presenc...</td>\n",
              "      <td>1216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>V- INCAPACIDAD\\nA la fecha del examen medico l...</td>\n",
              "      <td>incapacidad fecha examen medico legal estima j...</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>VI- CONSIDERACIONES MEDICO LEGALES\\nSi bien la...</td>\n",
              "      <td>consideraciones medico legales determinacion r...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>VII- CONCLUSION:\\n- Cuadro fisico: Lumbalgia p...</td>\n",
              "      <td>conclusion cuadro fisico lumbalgia postraumati...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>VIII- BIBLIOGRAFIA CONSULTADA:\\n-Tabla de Eval...</td>\n",
              "      <td>bibliografia consultada tabla evaluacion incap...</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>IX- PETITORIO\\nHabiendo finalizado el trabajo ...</td>\n",
              "      <td>petitorio habiendo finalizado trabajo endado r...</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>I.- DATOS PERSONALES\\nNombre y apellido: Espin...</td>\n",
              "      <td>datos personales nombre apellido espinosa carl...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>II.- MOTIVO DE RECLAMO Y DATOS LABORALES\\nTipo...</td>\n",
              "      <td>motivo reclamo datos laborales tipo reclamo ac...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>III.- ANTECEDENTES DE LOS HECHOS EN LITIS\\nEl ...</td>\n",
              "      <td>antecedentes hechos litis actor refiere encont...</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>IV.-ANTECEDENTES MEDICOS\\n1.- Antecedentes Her...</td>\n",
              "      <td>antecedentes medicos antecedentes heredo famil...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2672af9a-3c9d-48ac-b678-ec47adf1fee7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2672af9a-3c9d-48ac-b678-ec47adf1fee7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2672af9a-3c9d-48ac-b678-ec47adf1fee7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfnr.palabras.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MffxhHZbbzVY",
        "outputId": "31e89768-2c72-4533-afa4-3fd384f1b412"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    4111.000000\n",
              "mean      246.966188\n",
              "std       389.919628\n",
              "min         1.000000\n",
              "25%        42.000000\n",
              "50%       103.000000\n",
              "75%       304.500000\n",
              "max      5970.000000\n",
              "Name: palabras, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oQMxZ6EzNLQ"
      },
      "source": [
        "# Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk_dQGL0zJdp"
      },
      "outputs": [],
      "source": [
        "#Con min_df= 0.5 queda (4111,3)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfvectorizer = TfidfVectorizer( stop_words=stop_ws ,max_df=0.90, min_df=0.05, ngram_range=(1,1))\n",
        "Xtf = tfvectorizer.fit_transform(lemm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c540hkEmzTq_"
      },
      "outputs": [],
      "source": [
        "Xtf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WETcB6hyzaH6"
      },
      "outputs": [],
      "source": [
        "## reduccion de dimensionalidad : quitamos outliers? (valores atipicos)\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "svd = TruncatedSVD(n_components=10, algorithm='randomized', random_state=12)\n",
        "normalizer = Normalizer(copy=False) # kmeans de sklearn no tiene dist coseno\n",
        "lsa = make_pipeline(svd, normalizer)\n",
        "\n",
        "X1 = lsa.fit_transform(Xtf)\n",
        "X1.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svd.explained_variance_ratio_.sum()"
      ],
      "metadata": {
        "id": "fMD1eXkTYKCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_4cxPzozkQl"
      },
      "source": [
        "# Análisis de clusters: KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrsQsv8Zzlus"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "Sum_of_squared_distances = []\n",
        "K = range(1,20)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k, init='k-means++', n_init=10, verbose=False, random_state=12, algorithm = 'full')\n",
        "    km = km.fit(X1)\n",
        "    Sum_of_squared_distances.append(km.inertia_)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sumas de distancias al cuadrado')\n",
        "plt.title('Método del codo para k óptimo')\n",
        "plt.savefig('elbowmethod.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_anHF66zpwL"
      },
      "outputs": [],
      "source": [
        "km_clust = KMeans(n_clusters=10, init='k-means++', n_init=10, verbose=False, random_state=12)\n",
        "km_clust.fit(X1)\n",
        "dfnr['cluster']= km_clust.labels_\n",
        "dfnr.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px0aNTCizx7T"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.countplot(x= 'cluster', data=dfnr)\n",
        "plt.savefig('cluster_frec_kmeans.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcasDQkRz51x"
      },
      "outputs": [],
      "source": [
        "k=km_clust.n_clusters\n",
        "BOLD = '\\033[1m'\n",
        "END = '\\033[0m'\n",
        "for i in range(k):\n",
        "\n",
        "  print (BOLD+'\\n Frases del Cluster {}\\n'.format(i)+END,end='\\n')\n",
        "  print (dfnr[dfnr.cluster==i].seccion_limpia[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIvIiu4D0B_C"
      },
      "outputs": [],
      "source": [
        "def show_wordcloud(data, title = None):\n",
        "    wordcloud = WordCloud().generate(str(data))\n",
        "    fig = plt.figure(1, figsize=(6, 6))\n",
        "    plt.axis('off')\n",
        "    if title: \n",
        "        fig.suptitle(title, fontsize=20)\n",
        "        fig.subplots_adjust(top=2.3)\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.show()\n",
        "\n",
        "#show_wordcloud(dfnr[dfnr.label==5].clean)\n",
        "\n",
        "for i in range(km_clust.n_clusters):\n",
        "  \n",
        "\n",
        "  plt.title('Cluster {}'.format(i))\n",
        "\n",
        "  show_wordcloud(dfnr[dfnr.cluster==i].seccion_limpia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTQOTGW07NcH"
      },
      "source": [
        "# Latent Dirichlet Allocation (LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUQgmOEm7Yo2"
      },
      "outputs": [],
      "source": [
        "#Con min_df=0.5 queda (4111,3)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, stop_words=stop_ws, ngram_range=(1,1), min_df=0.10)\n",
        "tf = tf_vectorizer.fit_transform(lemm)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "tf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXlJFFyF7qcg"
      },
      "outputs": [],
      "source": [
        "lda = LDA(n_components=10, max_iter=15, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
        "lda.components_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVncFIA1723Y"
      },
      "outputs": [],
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        message = \"Topic #%d: \" % topic_idx\n",
        "        message += \" \".join([feature_names[i]\n",
        "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "        print(message)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O5z7Yfh79ex"
      },
      "outputs": [],
      "source": [
        "# Se muestran las 5 palabras más frecuentes de cada tema que encontró LDA\n",
        "\n",
        "print(\"\\nTopics in LDA model:\")\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "print_top_words(lda, tf_feature_names, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IExrox08A1f"
      },
      "outputs": [],
      "source": [
        "doc_topic = lda.transform(tf)\n",
        "lda_labels = [doc_topic[i].argmax() for i in range(doc_topic.shape[0])]\n",
        "dfnr['lda'] = lda_labels\n",
        "doc_topic.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZocHv5pdUKb"
      },
      "outputs": [],
      "source": [
        "BOLD = '\\033[1m'\n",
        "END = '\\033[0m'\n",
        "for i in range(doc_topic.shape[1]):\n",
        "\n",
        "  print (BOLD+'\\n Frases del tema {}\\n'.format(i)+END,end='\\n')\n",
        "  print (dfnr[dfnr.lda==i].seccion_limpia[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_L6nfSKdp6S"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.countplot(x= 'lda', data=dfnr)\n",
        "plt.savefig('frecs_lda.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8twnCfLk826I"
      },
      "source": [
        "# Reduccion de dimensionalidad: tSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK0L13X28jvH"
      },
      "outputs": [],
      "source": [
        "lda.components_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxeZ5-wm88LB"
      },
      "outputs": [],
      "source": [
        "#  incrustación de vecinos estocásticos distribuidos en t\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def plot_tsne(model, label):\n",
        "  X_tsne = TSNE(n_components=2).fit_transform(model)\n",
        "  tsne_df = pd.DataFrame({'X':X_tsne[:,0],\n",
        "                          'Y':X_tsne[:,1],\n",
        "                          'Z':label})\n",
        "  plt.figure(figsize=(20,10))\n",
        "  sns.scatterplot(x=\"X\", y=\"Y\",\n",
        "                hue='Z',\n",
        "                palette= 'bright',\n",
        "                legend='full',\n",
        "                data=tsne_df);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-mw_tMJ9Ee_"
      },
      "outputs": [],
      "source": [
        "plot_tsne(X1, dfnr.cluster)# hacemos reduccion de dimensionalidad del modelo de k-means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILkZxK2E9qGO"
      },
      "outputs": [],
      "source": [
        "dfnr.lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_iRGt8-9dog"
      },
      "outputs": [],
      "source": [
        "plot_tsne(doc_topic, dfnr.lda)# hacemos reduccion de dimensionalidad de LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZh8fx-y98aC"
      },
      "outputs": [],
      "source": [
        "X_tsne = TSNE(n_components=2, perplexity=200).fit_transform(doc_topic)\n",
        "tsne_df = pd.DataFrame({'X':X_tsne[:,0],\n",
        "                          'Y':X_tsne[:,1],\n",
        "                          'Z':dfnr.lda})\n",
        "plt.figure(figsize=(20,10))\n",
        "sns.scatterplot(x=\"X\", y=\"Y\",\n",
        "              hue='Z',\n",
        "              palette= 'bright',\n",
        "              legend='full',\n",
        "              data=tsne_df);\n",
        "plt.title('Reduccion de dimensionalidad del LDA con t-SNE')\n",
        "plt.savefig('lda_tsne.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fol2_Tiui-Az"
      },
      "source": [
        "#Otra prueba de LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6C_0bVNjBcP"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# initialize the vectorizer\n",
        "vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=0.10, max_df=0.95)\n",
        "# fit_transform applies TF-IDF to clean texts - we save the array of vectors in X\n",
        "X = vectorizer.fit_transform(lemm)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgkHwgFmjVpT"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=10)\n",
        "lda.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njq-kk3Tj697"
      },
      "outputs": [],
      "source": [
        "lda_dtf=lda.fit_transform(X)\n",
        "lda_dtf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXdtgnDXj-LL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "sorting=np.argsort(lda.components_)[:,::-1]\n",
        "features=np.array(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ivjqmt8kPbO"
      },
      "outputs": [],
      "source": [
        "!pip install mglearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjHNmlGVkBKU"
      },
      "outputs": [],
      "source": [
        "import mglearn\n",
        "\n",
        "mglearn.tools.print_topics(topics=range(8), feature_names=features, sorting=sorting, topics_per_chunk=5, n_words=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-LaYNecWv0x"
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_2CtdRL-lqM"
      },
      "source": [
        "#### Reducción con UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4O7mJHvMFwl"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "\n",
        "reducer = umap.UMAP(#random_state=42,\n",
        "#                     init='random',\n",
        "                    n_components=2,\n",
        "                    n_neighbors=300,\n",
        "                    min_dist=0.1,\n",
        "#                     spread=2,\n",
        "                    metric='euclidean',\n",
        "                    verbose=True)\n",
        "\n",
        "reducer.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reducer.transform(X)"
      ],
      "metadata": {
        "id": "Z3Fkng4qchpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXuR2kmuaxWW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40,40),facecolor='w')\n",
        "\n",
        "\n",
        "# fig, ax = plt.subplots(facecolor='w')\n",
        "plt.axis('off')\n",
        "plt.scatter(reducer.embedding_[:, 0], reducer.embedding_[:, 1], s=2.5,c='red')\n",
        "\n",
        "\n",
        "#     ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "#     ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "\n",
        "reducer2 = umap.UMAP(#random_state=42,\n",
        "#                     init='random',\n",
        "                    n_components=2,\n",
        "                    n_neighbors=300,\n",
        "                    min_dist=0.1,\n",
        "#                     spread=2,\n",
        "                    metric='cosine',\n",
        "                    verbose=True)\n",
        "\n",
        "matrixT= reducer2.fit_transform(X)\n",
        "matrixT"
      ],
      "metadata": {
        "id": "hLUw-v1Xgkh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(40,40),facecolor='w')\n",
        "\n",
        "\n",
        "# fig, ax = plt.subplots(facecolor='w')\n",
        "plt.axis('off')\n",
        "plt.scatter(reducer2.embedding_[:, 0], reducer2.embedding_[:, 1], s=2.5,c='red')\n",
        "\n",
        "\n",
        "#     ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "#     ax.set_axis_off()"
      ],
      "metadata": {
        "id": "d_Osqicuj2XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CJvchyQfhoDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap"
      ],
      "metadata": {
        "id": "yOQG3eyGshVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapper = umap.UMAP().fit(X)"
      ],
      "metadata": {
        "id": "Ih35Grqhs6lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap.plot"
      ],
      "metadata": {
        "id": "IKunuGyMtR1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l56JB2sMtWcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bYVnjwIoLUzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Kmean-Lda.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNO+I7t6Tsz2yKxpdMjxU/u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}