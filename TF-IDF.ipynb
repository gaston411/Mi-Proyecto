{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de texto\n",
    "### Creación de los dataframe y limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "df = pd.read_csv('pericias_medicas.csv', sep=',',  encoding='utf-8')\n",
    "#convierte en string los datos de la columna text\n",
    "df1 = df['text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de texto\n",
    "# Primera etapa de la limpieza de texto\n",
    "import re, string, unicodedata\n",
    "'''\n",
    "Se hace la eliminacion de texto entre corchetes, acentos, signos de puntuacion (excepto . y :), palabras con numeros.\n",
    "Se eliminan los espacios de sobra\n",
    "Se eliminan \\r, \\t, \\v, \\f, \\a\n",
    "'''\n",
    "def limpiarTexto1(txt: str, bert=False, nums=False) -> str:\n",
    "    \"\"\"\n",
    "    Elimina caracteres no deseados\n",
    "    Params:\n",
    "        **txt**:texto a ser limpiado de caracteres no desaeados\n",
    "    \"\"\"\n",
    "    if nums:\n",
    "        txt = re.sub(r'\\d+', ' ', txt)\n",
    "    if not bert:\n",
    "        txt = txt.translate(str.maketrans(\n",
    "            'áéíóúýàèìòùÁÉÍÓÚÀÈÌÒÙÝ', 'aeiouyaeiouAEIOUAEIOUY'))\n",
    "\n",
    "    '''\n",
    "    Eliminamos caracteres especiales: tabulador orizontal(\\t), tabulador vertical(\\v), \n",
    "    retorno de carro(\\r), avance de pagina(\\f), \n",
    "    caracter de retroceso: Marca el límite de una palabra(\\b), \n",
    "    '''\n",
    "    txt = txt.replace('\\r', ' ').replace(\"\\v\", ' ').replace(\n",
    "        \"\\t\", ' ').replace(\"\\f\", ' ').replace(\"\\a\", ' ').replace(\"\\b\", ' ')\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    return txt\n",
    "df1 = df1.apply(str)\n",
    "df1 = df1.apply(limpiarTexto1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def limpiarTexto(text):\n",
    "    text = re.sub(r'[-,;+º*?¿!¡<>{}()// %&´\"\"]',' ',text)\n",
    "    text = re.sub('^ +',' ',text)\n",
    "    text = re.sub('\\n ','',text)\n",
    "    text = re.sub('\\n\\n+','\\n',text)\n",
    "    text = re.sub(' +\\n','\\n',text)\n",
    "    #text = re.sub('\\. \\n','\\.\\n',text)\n",
    "    text = re.sub('\\d\\n','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('¨[... ]','',text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(' +',' ',text)\n",
    "    text = re.sub('^ +','',text)\n",
    "    text = re.sub('n.º.','',text)\n",
    "    text = re.sub('[a-zA-z-.]@[a-zA-Z].com','',text)\n",
    "    text = re.sub('\\d+','',text)\n",
    "    text = re.sub(r'^ ix|iv|vi+|i+x |(i{2,3})','', text) #dejar los numeros romanos\n",
    "\n",
    "    text = re.sub(' +\\n+','\\n',text)\n",
    "    text = re.sub('\\n+','\\n',text)\n",
    "    text = re.sub('\\d+\\n','',text)\n",
    "    #text = text.strip().replace('\\n','')\n",
    "    return text\n",
    "\n",
    "dfLimpio = df1.apply(limpiarTexto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda fase de limpieza\n",
    "# Se eliminan todos los elementos que meten ruido al texto y que no fueron eliminados en la fase de limpieza 1.\n",
    "import re\n",
    "\n",
    "def limpiarTexto2(text):\n",
    "    text = re.sub('^ ',' ',text)\n",
    "    text = re.sub('\\n +\\n','\\n',text)\n",
    "    text = re.sub(' +\\n\\n','\\n',text)\n",
    "    text = re.sub('\\n\\n+','\\n',text)\n",
    "    text = re.sub(' \\n','\\n',text)\n",
    "    text = re.sub('\\d\\n','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('\\u200b\\n','',text)\n",
    "    text = re.sub('\\d{3,100}','',text)\n",
    "    text = re.sub('\\d+-\\d+','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('[nN]º|[nN][. ]º','',text)\n",
    "    text = re.sub('[º<>/]','',text)\n",
    "    text = re.sub('\\d{3,100}','',text)\n",
    "    text = re.sub('[a-zA-z-.]+@[a-zA-Z]+.com','',text)\n",
    "    return text\n",
    "\n",
    "df1 = df1.apply(limpiarTexto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercera fase de limpieza\n",
    "# Eliminamos las lineas que no son de utilidad para el analisis o que van a afectar los resultados del mismo.\n",
    "# Ejemplo de linea eliminada: las lineas que comienzan con \"Se encuentra contestada en.....\"\n",
    "import re\n",
    "\n",
    "def limpiarTexto3(text):\n",
    "    text = re.sub('[a-z1-9.]+[).-] [s|S]e encuentra contestad[a|o] .+[. \\n]','',text)\n",
    "    text = re.sub('[0-9]+[. ]+[yY]a fue contestado.+[.\\n]','',text)\n",
    "    text = re.sub('[fF]oja [1-9].+\\n', '', text)\n",
    "    text = re.sub('[pP]regunta[ 0-9]+[)].+\\n|[rR]espuesta[ 0-9]+[)].+\\n','',text)#elimina oraciones comenzadas en preguta/respuesta.\n",
    "    text = re.sub('V[. ]+S.', '', text)\n",
    "    #text = re.sub('[IV]+.[A-Z]{1,3}[\\n.]', '', text)\n",
    "    text = re.sub('[I][.][P][.]','',text)\n",
    "    text = re.sub('[I][.][T][.]','',text)\n",
    "    text = re.sub('[I][.][A][.]','',text)\n",
    "    text = re.sub('[I][.][L][.]','',text)\n",
    "    text = re.sub('[I][.][B][.]','',text)\n",
    "    text = re.sub('[I][.][N][.]','',text)\n",
    "    text = re.sub('[I][.][V][.]','',text)\n",
    "    text = re.sub('[V][.][M][.]','',text)\n",
    "    text = re.sub('[V][.][A][.]','',text)\n",
    "\n",
    "    return text\n",
    "\n",
    "dfLimpio = df1.apply(limpiarTexto3)\n",
    "dfLimpio = dfLimpio.apply(limpiarTexto2)\n",
    "#pprint(dfLimpio[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busqueda de titulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['II). PREAMBULO.',\n",
      " 'III). ANTECEDENTES DE INTERES MEDICO PRESENTE EN AUTOS.',\n",
      " 'IV) EXAMEN DEL PERITO DE OFICIO.',\n",
      " 'V) CONSIDERACIONES MEDICAS:',\n",
      " 'VII) CONTESTACION DE PUNTOS PERICIALES.',\n",
      " 'VIII) BIBLIOGRAFIA.',\n",
      " 'VII) CONCLUSIONES:',\n",
      " 'IX). PETITORIO.']\n"
     ]
    }
   ],
   "source": [
    "# Busca títulos en mayusculas\n",
    "def buscarTitulosMayusculas(text):\n",
    "    # Expresiín regular para encontrar títulos en mayusculas.\n",
    "    tituloMayusculas =re.compile(r'(I{1,3}|IV|V|VI{1,3}|IX|X)[-.)]+[A-Z -]+[\\:\\.\\n]') #[1-9]|\n",
    "    titulosMayusculasEncontrados = []\n",
    "\n",
    "    for m in tituloMayusculas.finditer(text):\n",
    "        titulosMayusculasEncontrados.append(m.group())\n",
    "\n",
    "    return titulosMayusculasEncontrados\n",
    "# titulosMAyuscula: lista que guarda los títulos en mayusculas\n",
    "titulosMayusculas=[]\n",
    "for expediente in dfLimpio:\n",
    "    titulosMayusculas.append(buscarTitulosMayusculas(expediente))\n",
    "\n",
    "dfTitulosMayusculasConStops= pd.DataFrame(titulosMayusculas)\n",
    "\n",
    "pprint(titulosMayusculas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-PROEMIO:',\n",
      " 'II-ANTECEDENTES DE INTERES MEDICO-LEGAL:',\n",
      " 'III-EXAMEN FISICO DEL ACTOR:',\n",
      " 'IV-CONSIDERACIONES MEDICO-LEGALES:',\n",
      " 'VII-CONCLUSIONES.',\n",
      " 'VII-INCAPACIDAD:',\n",
      " 'IX-PETITORIO:']\n"
     ]
    }
   ],
   "source": [
    "pprint(titulosMayusculas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ultima limpieza de titulos\n",
    "# def limpiarTitulosHTML(text):\n",
    "#     text = re.sub('\\n','',text)\n",
    "#     text = re.sub(' +',' ',text)\n",
    "#     #text = re.sub('[n]','',text)\n",
    "#     #text = re.sub('[\\\\\\]',' ',text)\n",
    "#     return text\n",
    "# titulosMayusculas = limpiarTitulosHTML(str(titulosMayusculas))\n",
    "# dfTitulosMayusculasConStops = dfTitulosMayusculasConStops.apply(str)\n",
    "# dfTitulosMayusculasConStops = dfTitulosMayusculasConStops.apply(limpiarTitulosHTML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titulos y ubicacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('IV) EXAMEN DEL PERITO DE OFICIO.', 5035, 5067, 32),\n",
      " ('V) CONSIDERACIONES MEDICAS:', 32819, 32846, 27),\n",
      " ('VII) CONTESTACION DE PUNTOS PERICIALES.', 43724, 43763, 39),\n",
      " ('VIII) BIBLIOGRAFIA.', 45065, 45084, 19),\n",
      " ('VII) CONCLUSIONES:', 45833, 45851, 18)]\n"
     ]
    }
   ],
   "source": [
    "# Encontrar la ubicacion del titulo en el documento\n",
    "titulosPosicion=[]\n",
    "\n",
    "for titulo in titulosMayusculas[1]:\n",
    "    inicioTitulo = dfLimpio[1].index(titulo)\n",
    "    palabrasPorTitulo = len(titulo)\n",
    "    finalTitulo = inicioTitulo + palabrasPorTitulo\n",
    "    titulosPosicion.append((titulo, inicioTitulo, finalTitulo, palabrasPorTitulo))\n",
    "\n",
    "pprint(titulosPosicion)\n",
    "\n",
    "\n",
    "#anotar parrafos entre titulos.\n",
    "#parrafo = texto[inicio:inicio+1]\n",
    "#mostrar las secciones\n",
    "#estadisiticas de titulos interdocumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(dfLimpio[1][32819:43723])\n",
    "parrafoConsideraciones = dfLimpio[1][32819:43723]\n",
    "pprint(parrafoConsideraciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe para colocar el salto de linea en formato HTML\n",
    "dfLimpioHTML = dfLimpio.apply(str)\n",
    "def limpiarTextoHTML(text):\n",
    "    text = text.strip().replace('\\n','<br>')\n",
    "    return text\n",
    "\n",
    "dfLimpioHTML = dfLimpioHTML.apply(limpiarTextoHTML)\n",
    "parrafoConsideraciones = limpiarTextoHTML(parrafoConsideraciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'procedimientos': '#cd5c5c',\n",
    "    'cuerpos': '#99ccff',\n",
    "    'afecciones': '#ffa500'\n",
    "}\n",
    "\n",
    "body = f'''\n",
    "        <p>\n",
    "        {dfLimpioHTML[1]}\n",
    "        </p>\n",
    "        <br>\n",
    "        '''\n",
    "body = body.replace(parrafoConsideraciones,f'<span style=\"background-color: #99ccff\">{parrafoConsideraciones}</span>')\n",
    "for titulo in titulosMayusculas[1]:\n",
    "    body = body.replace(titulo,f'<span style=\"background-color: #cd5c5c\">{titulo}</span>')\n",
    "with open('parrafos.html','w', encoding=\"utf-8\") as f:\n",
    "    f.write(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f7c04c36d0b751253b9619efb75c537c6c26f8df6c81e91ba988c38192421cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
