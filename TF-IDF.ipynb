{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "df = pd.read_csv(\"pericias_medicas.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "df = df['text'].apply(str)\n",
    "df1 = df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'o'\n"
     ]
    }
   ],
   "source": [
    "#pprint(df[0][22674])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def limpiarTexto(text):\n",
    "    text = re.sub(r'[-,;+º*?¿!¡<>{}()// %&´\"\"]',' ',text)\n",
    "    text = re.sub('^ +',' ',text)\n",
    "    text = re.sub('\\n ','',text)\n",
    "    text = re.sub('\\n\\n+','\\n',text)\n",
    "    text = re.sub(' +\\n','\\n',text)\n",
    "    #text = re.sub('\\. \\n','\\.\\n',text)\n",
    "    text = re.sub('\\d\\n','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('¨[... ]','',text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(' +',' ',text)\n",
    "    text = re.sub('^ +','',text)\n",
    "    text = re.sub('n.º.','',text)\n",
    "    text = re.sub('[a-zA-z-.]@[a-zA-Z].com','',text)\n",
    "    text = re.sub('\\d+','',text)\n",
    "    text = re.sub(r'^ ix|iv|vi+|i+x |(i{2,3})','', text) #dejar los numeros romanos\n",
    "\n",
    "    text = re.sub(' +\\n+','\\n',text)\n",
    "    text = re.sub('\\n+','\\n',text)\n",
    "    text = re.sub('\\d+\\n','',text)\n",
    "    #text = text.strip().replace('\\n','')\n",
    "    return text\n",
    "\n",
    "dfLimpio = df1.apply(limpiarTexto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dfLimpio[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stops = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "#elimino stopwords\n",
    "def remove_stops(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Función que elimina stopwords\n",
    "    Params:\n",
    "        **texto**:texto a ser limpiado de stopwords\n",
    "\n",
    "    \"\"\"\n",
    "    texto = [\n",
    "        i for i in texto.split() if i not in stops\n",
    "    ]\n",
    "    return texto\n",
    "\n",
    "df1.apply(str)\n",
    "df1 = df1.apply(remove_stops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expresion regular para encontrar los titulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"[' antecedentes de interes medico legal:', ' examen fisico del actor:', ' \"\n",
      " \"semiologia de las afecciones:', ' consideraciones medico legales:']\")\n"
     ]
    }
   ],
   "source": [
    "#creo un nuevo data frame de titulos\n",
    "#titulos1 = (re.findall(r'\\n[a-z- \\.]+:\\n', df1[0]))\n",
    "\n",
    "def buscarTitulos(text):\n",
    "    text = re.sub(r' +',' ', text)\n",
    "    text = re.sub(r'\\n[a-z]','\\n [a-z]', text)\n",
    "    titulosBuscados = re.findall(r'\\n[a-z- ]+[:]\\n', text)\n",
    "    return titulosBuscados\n",
    "\n",
    "def limpiarTitulos(text):\n",
    "    text = re.sub(r'\\\\n','', text)\n",
    "    text = re.sub(r' +',' ', text)\n",
    "    text = re.sub(r'^ ','', text)\n",
    "    text = re.findall(r'[a-z ]+:', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "dfTitulos = dfLimpio.apply(buscarTitulos)\n",
    "dfTitulos = dfTitulos.apply(str)\n",
    "dfTitulos = dfTitulos.apply(limpiarTitulos)\n",
    "dfTitulos = dfTitulos.apply(str)\n",
    "pprint(dfTitulos[0])\n",
    "#HACER ESTADISTICAS DE TITULOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' antecedentes de interes medico legal:', 696, 734, 38),\n",
      " (' examen fisico del actor:', 2071, 2096, 25),\n",
      " (' semiologia de las afecciones:', 5021, 5051, 30),\n",
      " (' consideraciones medico legales:', 9227, 9259, 32)]\n",
      "'cantidad de titulos:'\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#lista de titulos y ubicacion\n",
    "dfTitulos = dfTitulos.apply(str)\n",
    "titulos = (re.findall(r'[a-z- ]+:', dfTitulos[0]))\n",
    "titulosPosicion=[]\n",
    "for i,j in enumerate(titulos):\n",
    "    inicio = dfLimpio[0].index(titulos[i])\n",
    "    final = inicio + (len(titulos[i]))\n",
    "    palabrasPorTitulo = final-inicio\n",
    "    titulosPosicion.append((titulos[i], inicio,final, palabrasPorTitulo))\n",
    "pprint(titulosPosicion)\n",
    "pprint('cantidad de titulos:')\n",
    "cantTitulos = len(titulos)\n",
    "pprint(cantTitulos)\n",
    "#anotar parrafos entre titulos.\n",
    "#parrafo = texto[inicio:inicio+1]\n",
    "#mostrar las secciones\n",
    "#estadisiticas de titulos interdocumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dfLimpio[0]\n",
    "#doc = limpiarTexto(doc)\n",
    "#pprint(f'{doc[22673]} , {doc[22674]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'procedimientos': '#cd5c5c',\n",
    "    'cuerpos': '#99ccff',\n",
    "    'afecciones': '#ffa500'\n",
    "}\n",
    "\n",
    "body = f'''\n",
    "        <p>\n",
    "        {doc[0]}\n",
    "        </p>\n",
    "        <br>\n",
    "        '''\n",
    "for titulo in titulos:\n",
    "    body = body.replace(titulo,f'<span style=\"background-color: #99ccff\">{titulo}</span>')\n",
    "with open('titulos.html', 'w') as f:\n",
    "    f.write(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "stops = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "#elimino stopwords\n",
    "def remove_stops(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Función que elimina stopwords\n",
    "    Params:\n",
    "        **texto**:texto a ser limpiado de stopwords\n",
    "\n",
    "    \"\"\"\n",
    "    texto = [\n",
    "        i for i in texto.split() if i not in stops\n",
    "    ]\n",
    "    return texto\n",
    "\n",
    "df1 = df1.apply(remove_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dfTitulos)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f7c04c36d0b751253b9619efb75c537c6c26f8df6c81e91ba988c38192421cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
