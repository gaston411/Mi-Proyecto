{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pericias_medicas.csv',  encoding='latin-1')\n",
    "df = df['text'].apply(str)\n",
    "\n",
    "#print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIMPIEZA DE TEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text\n",
      "0        informa a continuacia3n    j t    perito me...\n",
      "1        juzg     perito medico presenta informe mad...\n",
      "2     expediente nao cnt      juzgado nacional de  i...\n",
      "3     juzgado nacional de trabajo        lavalle    ...\n",
      "4           perito presenta informe                 ...\n",
      "...                                                 ...\n",
      "3801           trabajo nao    presento pericia madic...\n",
      "3802        jnt  nao    a  parana    a    ao  piso  ...\n",
      "3803     ii   historia clinica     se dirige a v s y...\n",
      "3804  perito psicalogo informa segunda incomparecenc...\n",
      "3805  juzgado nacional del trabajo na     tte  gral ...\n",
      "\n",
      "[3806 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Limpieza de texto\n",
    "import re, string, unicodedata\n",
    "#se hace la eliminacion de texto entre corchetes, acentos, signos de puntuacion, palabras con numeros, coloca el texto en minuscula.\n",
    "def limpiarTexto(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?¿\\]\\%', ' ', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('[‘’“”…«»]', '', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\r', ' ', text)\n",
    "    text = str(unicodedata.normalize('NFKD', text).encode('ascii','ignore'))[2:-1]\n",
    "    return text\n",
    "\n",
    "round = lambda x: limpiarTexto(x)\n",
    "df1 = pd.DataFrame(df.apply(round))\n",
    "\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminacion de stopwords y lematizacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WordListCorpusReader' object has no attribute 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-3889ff2897d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'spanish'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#corpus.stopwords.words('spanish')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# black_list = json.load(open('black_list.json', 'r'))['black_list']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WordListCorpusReader' object has no attribute 'word'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "stops = nltk.corpus.stopwords.word('spanish')\n",
    "#corpus.stopwords.words('spanish')\n",
    "# black_list = json.load(open('black_list.json', 'r'))['black_list']\n",
    "# black_list = json.load(open('utils/black_list.json', 'r'))['black_list']\n",
    "#black_list = utils_fun.open_json('utils/black_list.json')['black_list']\n",
    "\n",
    "#elimino stopword\n",
    "def remove_stops(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Función que elimina stopwords\n",
    "    Params:\n",
    "        **texto**:texto a ser limpiado de stopwords\n",
    "\n",
    "    \"\"\"\n",
    "    texto = [\n",
    "        i for i in texto.split() if i not in stops\n",
    "    ]\n",
    "\n",
    "df2 = df1['text'].apply(remove_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6598166c970a47e7821424993c254687b8a79b8ac255184d876b10779f30e06d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
