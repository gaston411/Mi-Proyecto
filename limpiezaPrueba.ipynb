{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos librerías - Creamos el dataframe de pericias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "df = pd.read_csv('pericias_medicas.csv', sep=',',  encoding='utf-8')\n",
    "#convierte en string los datos de la columna text\n",
    "df = df['text'].apply(str)\n",
    "df1 = df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de texto\n",
    "# Primera etapa de la limpieza de texto\n",
    "import re, string, unicodedata\n",
    "'''\n",
    "Se hace la eliminacion de texto entre corchetes, acentos, signos de puntuacion (excepto . y :), palabras con numeros.\n",
    "Se eliminan los espacios de sobra\n",
    "Se eliminan \\r, \\t, \\v, \\f, \\a\n",
    "'''\n",
    "def limpiarTexto1(txt: str, bert=False, nums=False) -> str:\n",
    "    \"\"\"\n",
    "    Elimina caracteres no deseados\n",
    "    Params:\n",
    "        **txt**:texto a ser limpiado de caracteres no desaeados\n",
    "    \"\"\"\n",
    "    if nums:\n",
    "        txt = re.sub(r'\\d+', ' ', txt)\n",
    "    if not bert:\n",
    "        txt = txt.translate(str.maketrans(\n",
    "            'áéíóúýàèìòùÁÉÍÓÚÀÈÌÒÙÝ', 'aeiouyaeiouAEIOUAEIOUY'))\n",
    "\n",
    "    '''\n",
    "    Eliminamos caracteres especiales: tabulador orizontal(\\t), tabulador vertical(\\v), \n",
    "    retorno de carro(\\r), avance de pagina(\\f), \n",
    "    caracter de retroceso: Marca el límite de una palabra(\\b), \n",
    "    '''\n",
    "    txt = txt.replace('\\r', ' ').replace(\"\\v\", ' ').replace(\n",
    "        \"\\t\", ' ').replace(\"\\f\", ' ').replace(\"\\a\", ' ').replace(\"\\b\", ' ')\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    return txt\n",
    "df1.apply(str)\n",
    "df1 = df1.apply(limpiarTexto1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda fase de limpieza\n",
    "# Se eliminan todos los elementos que meten ruido al texto y que no fueron eliminados en la fase de limpieza 1.\n",
    "import re\n",
    "\n",
    "def limpiarTexto2(text):\n",
    "    text = re.sub('^ ',' ',text)\n",
    "    text = re.sub('\\n +\\n','\\n',text)\n",
    "    text = re.sub(' +\\n\\n','\\n',text)\n",
    "    text = re.sub('\\n\\n+','\\n',text)\n",
    "    text = re.sub(' \\n','\\n',text)\n",
    "    text = re.sub('\\d\\n','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('\\u200b\\n','',text)\n",
    "    text = re.sub('\\d{3,100}','',text)\n",
    "    text = re.sub('\\d+-\\d+','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('[nN]º|[nN][. ]º','',text)\n",
    "    text = re.sub('[º<>/]','',text)\n",
    "    text = re.sub('\\d{3,100}','',text)\n",
    "    text = re.sub('[a-zA-z-.]+@[a-zA-Z]+.com','',text)\n",
    "    return text\n",
    "\n",
    "df1 = df1.apply(limpiarTexto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercera fase de limpieza\n",
    "# Eliminamos las lineas que no son de utilidad para el analisis o que van a afectar los resultados del mismo.\n",
    "# Ejemplo de linea eliminada: las lineas que comienzan con \"Se encuentra contestada en.....\"\n",
    "import re\n",
    "\n",
    "def limpiarTexto3(text):\n",
    "    text = re.sub('[a-z1-9.]+[).-] [s|S]e encuentra contestad[a|o] .+[. \\n]','',text)\n",
    "    text = re.sub('[0-9]+[. ]+[yY]a fue contestado.+[.\\n]','',text)\n",
    "    text = re.sub('[fF]oja [1-9].+\\n', '', text)\n",
    "    text = re.sub('[pP]regunta[ 0-9]+[)].+\\n|[rR]espuesta[ 0-9]+[)].+\\n','',text)#elimina oraciones comenzadas en preguta/respuesta.\n",
    "    return text\n",
    "\n",
    "dfLimpio = df1.apply(limpiarTexto3)\n",
    "dfLimpio = dfLimpio.apply(limpiarTexto2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda de títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Búsqueda de títulos\n",
    "# Se crea un nuevo dataframe de títulos según distintos criterios\n",
    "\n",
    "# busca titulos que comienzan con numeros romanos\n",
    "def buscarTitulosRomanos(text):\n",
    "    # Expresiones regulares para encontrar los numeros romanos\n",
    "    tituloNroRomano =re.compile(r'(I{1,3}|IV|V|VI{1,3}|IX|X)+[-.)][\\w\\s-]+[:\\n]')\n",
    "    tituloNroRomano5 =re.compile(r'V[-.)]+[\\w\\s-]+[:\\n]')\n",
    "    titulosRomanosEncontrados = []\n",
    "\n",
    "    for m in tituloNroRomano.finditer(text):\n",
    "        titulosRomanosEncontrados.append(m.group())\n",
    "    for m in tituloNroRomano5.finditer(text):\n",
    "        titulosRomanosEncontrados.append(m.group())\n",
    "        \n",
    "    return titulosRomanosEncontrados\n",
    "\n",
    "# titulosConNroRomano: lista que guarda los titulos que comienzan con numeros romanos   \n",
    "titulosConNroRomano=[]\n",
    "for expediente in dfLimpio:\n",
    "    titulosConNroRomano.append(buscarTitulosRomanos(expediente))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca títulos que comienzan con números latinos\n",
    "def buscarTitulosLatinos(text):\n",
    "    # Expresiún regular para encontrar tútulos que comienzan con números\n",
    "    tituloNroLatino =re.compile(r'[1-9][-.)][\\w\\s-]+[:\\n]')\n",
    "    titulosLatinosEncontrados = []\n",
    "\n",
    "    for m in tituloNroLatino.finditer(text):\n",
    "        titulosLatinosEncontrados.append(m.group())\n",
    "\n",
    "    return titulosLatinosEncontrados\n",
    "\n",
    "# titulosConNroLatino: lista que guarda los tútulos que comienzan con números latinos\n",
    "titulosConNroLatino=[]\n",
    "for expediente in dfLimpio:\n",
    "    titulosConNroLatino.append(buscarTitulosLatinos(expediente))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca títulos en mayusculas\n",
    "def buscarTitulosMayusculas(text):\n",
    "    # Expresiín regular para encontrar títulos en mayusculas.\n",
    "    tituloMayusculas =re.compile(r'([1-9]|I{1,3}|IV|V|VI{1,3}|IX|X)[-.)][A-Z -]+[:.\\n]')\n",
    "    titulosMayusculasEncontrados = []\n",
    "\n",
    "    for m in tituloMayusculas.finditer(text):\n",
    "        titulosMayusculasEncontrados.append(m.group())\n",
    "\n",
    "    return titulosMayusculasEncontrados\n",
    "# titulosMAyuscula: lista que guarda los títulos en mayusculas\n",
    "titulosMayusculas=[]\n",
    "for expediente in dfLimpio:\n",
    "    titulosMayusculas.append(buscarTitulosMayusculas(expediente))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de stopwords. Nueva limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "stops = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "# elimino stopwords\n",
    "def remove_stops(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Función que elimina stopwords\n",
    "    Params:\n",
    "        **texto**:texto a ser limpiado de stopwords\n",
    "\n",
    "    \"\"\"\n",
    "    texto = [\n",
    "        i for i in texto.split() if i not in stops\n",
    "    ]\n",
    "    return texto\n",
    "\n",
    "def limpiarTitulos(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n','',text)\n",
    "    text = re.sub(r'[a-z]\\.[a-z]\\.','',text)\n",
    "    text = re.sub(r'(i{2,3}|iv|vi{1,3}|ix)','',text)\n",
    "    text = re.sub(r'\\W',' ',text)    \n",
    "    text = re.sub(r'\\d+','',text)\n",
    "    text = re.sub(r' [a-z] ','',text)\n",
    "    \n",
    "    \n",
    "    return text\n",
    "\n",
    "# elimino stopwords y hago una última limpieza\n",
    "titulosMayusculasStop = limpiarTitulos(str(titulosMayusculas))\n",
    "titulosMayusculasStop = remove_stops(str(titulosMayusculasStop))\n",
    "titulosConNroLatinoStop = limpiarTitulos(str(titulosConNroLatino))\n",
    "titulosConNroLatinoStop = remove_stops(str(titulosConNroLatinoStop))\n",
    "titulosConNroRomanoStop = limpiarTitulos(str(titulosConNroRomano))\n",
    "titulosConNroRomanoStop = remove_stops(str(titulosConNroRomanoStop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASE DE ANALISIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de dataframes de títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear un df de títulos.\n",
    "import pandas as pd\n",
    "\n",
    "dfTitulosRomanos = pd.DataFrame(titulosConNroRomanoStop)\n",
    "dfTitulosLatinos= pd.DataFrame(titulosConNroLatinoStop)\n",
    "dfTitulosMayusculas= pd.DataFrame(titulosMayusculasStop)\n",
    "\n",
    "\n",
    "# dfTitulos = pd.DataFrame()\n",
    "# dfTitulos['latinos'] = titulosConNroLatinoStop\n",
    "# dfTitulos['romanos'] = pd.DataFrame(titulosConNroRomanoStop)\n",
    "# dfTitulos['mayusculas'] = pd.DataFrame(titulosMayusculasStop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titulos totales del dataframe original\n",
    "def contarPalabras(text):\n",
    "    totalPalabras = 0\n",
    "    for expediente in text:\n",
    "        p = expediente.split()\n",
    "        totalPalabras+=(len(p))\n",
    "    return totalPalabras\n",
    "\n",
    "# Total de palabras en el datrafame origina.\n",
    "palabrasTotalesDf = contarPalabras(df1)\n",
    "\n",
    "# Contadores de títulos\n",
    "# Total de titulos por tipo de busqueda\n",
    "contTitulosLatino = len(titulosConNroLatinoStop)\n",
    "contTitulosRomanos = len(titulosConNroRomanoStop)\n",
    "contTitulosmayusculas = len(titulosMayusculasStop)\n",
    "totalPalabrasTitulos = contTitulosLatino + contTitulosRomanos + contTitulosmayusculas\n",
    "\n",
    "# Mostrar por pantalla la cantidad de palabras por tituto, cantidad de palabras totales\n",
    "print(f'''Palabras en titulos ROMANOS:           {contTitulosRomanos}\n",
    "Palabras en titulos LATINOS:           {contTitulosLatino}\n",
    "Palabras en titulos con MAYUSCULAS:    {contTitulosmayusculas}\n",
    "\n",
    "TOTAL DE PALABRAS ENCONTRADAS EN TITULOS:   {totalPalabrasTitulos}\n",
    "\n",
    "TOTAL DE PALABRAS DEL DATAFRAME ORIGINAL:   {palabrasTotalesDf}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe de frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtengo la frecuencia relativa de las palabras de los titulos\n",
    "frecuenciaTitulosRomanos = dfTitulosRomanos.value_counts()\n",
    "frecuenciaTitulosLatinos = dfTitulosLatinos.value_counts()\n",
    "frecuenciaTitulosMayuscula = dfTitulosMayusculas.value_counts()\n",
    "\n",
    "# Crea un dataframe de frecuencias\n",
    "dfFrecuencias = pd.DataFrame()\n",
    "dfFrecuencias['latinos'] = frecuenciaTitulosLatinos\n",
    "dfFrecuencias['romanos'] = pd.DataFrame(frecuenciaTitulosRomanos)\n",
    "dfFrecuencias['mayuscula'] = pd.DataFrame(frecuenciaTitulosMayuscula)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar por pantalla la frecuencia de titulos\n",
    "print(f'''FRECUENCIA DE PALABRAS\n",
    "TITULOS EN MAYUSCULA\n",
    "{frecuenciaTitulosMayuscula[1:10]}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un grafico de torta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creacion de grafico de torta de la cantidad de titulos encontrados segun el tipo de busqueda\n",
    "cantTitulos = [contTitulosLatino, contTitulosRomanos, contTitulosmayusculas]\n",
    "nombreTitulos = ['Latinos', 'Romanos', 'Mayusculas']\n",
    "colores = ['#2C4AF1','#2CF168','#F12C2C']\n",
    "\n",
    "plt.pie(cantTitulos, labels=nombreTitulos, autopct= '%0.1f %%', colors=colores)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un grafico de torta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creacion de grafico de torta de la cantidad de titulos encontrados sobre la cantidad de palabras en total de dataframe\n",
    "cantPalabras = [palabrasTotalesDf, totalPalabrasTitulos]\n",
    "nombreTitulos = ['Palabras totales', 'Palabras en titulos']\n",
    "colores = ['#2C4AF1','#2CF168']\n",
    "desfase=(0,0.5)\n",
    "\n",
    "plt.pie(cantPalabras, labels=nombreTitulos, autopct= '%0.1f %%', colors=colores, explode=desfase) #, explode=desfase\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titulos totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos un vectorizador para ver las frecuencias de palabras por documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias necesarias.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "stops = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=set(stops))\n",
    "X = vectorizer.fit_transform(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(true_k): \n",
    "    print(f'Cluster %d:' % i, ), \n",
    "    for ind in order_centroids[i, :10]: \n",
    "        print(' %s' % terms[ind])   \n",
    "\n",
    "\n",
    "print('\\n') \n",
    "print('Predicción***************************') \n",
    "X = vectorizer.transform(['consideraciones medico legales']) \n",
    "predicted = model.predict(X)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Join the different processed titles together.\n",
    "long_string = ','.join(list(papers['paper_text_processed'].values))\n",
    "\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f7c04c36d0b751253b9619efb75c537c6c26f8df6c81e91ba988c38192421cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
