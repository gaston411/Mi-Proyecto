{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos librerías - Creamos el dataframe de pericias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "df = pd.read_csv('pericias_medicas.csv', sep=',',  encoding='utf-8')\n",
    "#convierte en string los datos de la columna text\n",
    "df1 = df['text'].apply(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de texto\n",
    "# Primera etapa de la limpieza de texto\n",
    "import re, string, unicodedata\n",
    "'''\n",
    "Se hace la eliminacion de texto entre corchetes, acentos, signos de puntuacion (excepto . y :), palabras con numeros.\n",
    "Se eliminan los espacios de sobra\n",
    "Se eliminan \\r, \\t, \\v, \\f, \\a\n",
    "'''\n",
    "def limpiarTexto1(txt: str, bert=False, nums=False) -> str:\n",
    "    \"\"\"\n",
    "    Elimina caracteres no deseados\n",
    "    Params:\n",
    "        **txt**:texto a ser limpiado de caracteres no desaeados\n",
    "    \"\"\"\n",
    "    if nums:\n",
    "        txt = re.sub(r'\\d+', ' ', txt)\n",
    "    if not bert:\n",
    "        txt = txt.translate(str.maketrans(\n",
    "            'áéíóúýàèìòùÁÉÍÓÚÀÈÌÒÙÝ', 'aeiouyaeiouAEIOUAEIOUY'))\n",
    "\n",
    "    '''\n",
    "    Eliminamos caracteres especiales: tabulador orizontal(\\t), tabulador vertical(\\v), \n",
    "    retorno de carro(\\r), avance de pagina(\\f), \n",
    "    caracter de retroceso: Marca el límite de una palabra(\\b), \n",
    "    '''\n",
    "    txt = txt.replace('\\r', ' ').replace(\"\\v\", ' ').replace(\n",
    "        \"\\t\", ' ').replace(\"\\f\", ' ').replace(\"\\a\", ' ').replace(\"\\b\", ' ')\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    return txt\n",
    "df1 = df1.apply(str)\n",
    "df1 = df1.apply(limpiarTexto1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda fase de limpieza\n",
    "# Se eliminan todos los elementos que meten ruido al texto y que no fueron eliminados en la fase de limpieza 1.\n",
    "import re\n",
    "\n",
    "def limpiarTexto2(text):\n",
    "    text = re.sub('^ ',' ',text)\n",
    "    text = re.sub('\\n +\\n','\\n',text)\n",
    "    text = re.sub(' +\\n\\n','\\n',text)\n",
    "    text = re.sub('\\n\\n+','\\n',text)\n",
    "    text = re.sub(' \\n','\\n',text)\n",
    "    text = re.sub('\\d\\n','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('\\u200b\\n','',text)\n",
    "    text = re.sub('\\d{3,100}','',text)\n",
    "    text = re.sub('\\d+-\\d+','',text)\n",
    "    text = re.sub('\\x0c','',text)\n",
    "    text = re.sub('[nN]º|[nN][. ]º','',text)\n",
    "    text = re.sub('[º<>/]','',text)\n",
    "    text = re.sub('\\d{3,100}','',text)\n",
    "    text = re.sub('[a-zA-z-.]+@[a-zA-Z]+.com','',text)\n",
    "    return text\n",
    "\n",
    "df1 = df1.apply(limpiarTexto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercera fase de limpieza\n",
    "# Eliminamos las lineas que no son de utilidad para el analisis o que van a afectar los resultados del mismo.\n",
    "# Ejemplo de linea eliminada: las lineas que comienzan con \"Se encuentra contestada en.....\"\n",
    "import re\n",
    "\n",
    "def limpiarTexto3(text):\n",
    "    text = re.sub('[a-z1-9.]+[).-] [s|S]e encuentra contestad[a|o] .+[. \\n]','',text)\n",
    "    text = re.sub('[0-9]+[. ]+[yY]a fue contestado.+[.\\n]','',text)\n",
    "    text = re.sub('[fF]oja [1-9].+\\n', '', text)\n",
    "    text = re.sub('[pP]regunta[ 0-9]+[)].+\\n|[rR]espuesta[ 0-9]+[)].+\\n','',text)#elimina oraciones comenzadas en preguta/respuesta.\n",
    "    text = re.sub('V[. ]+S.', '', text)\n",
    "    #text = re.sub('[IV]+.[A-Z]{1,3}[\\n.]', '', text)\n",
    "    text = re.sub('[I][.][P][.]','',text)\n",
    "    text = re.sub('[I][.][T][.]','',text)\n",
    "    text = re.sub('[I][.][A][.]','',text)\n",
    "    text = re.sub('[I][.][L][.]','',text)\n",
    "    text = re.sub('[I][.][B][.]','',text)\n",
    "    text = re.sub('[I][.][N][.]','',text)\n",
    "    text = re.sub('[I][.][V][.]','',text)\n",
    "    text = re.sub('[V][.][M][.]','',text)\n",
    "    text = re.sub('[V][.][A][.]','',text)\n",
    "\n",
    "    return text\n",
    "\n",
    "dfLimpio = df1.apply(limpiarTexto3)\n",
    "dfLimpio = dfLimpio.apply(limpiarTexto2)\n",
    "#pprint(dfLimpio[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busqueda de titulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca títulos en mayusculas\n",
    "def buscarTitulosMayusculas(text):\n",
    "    # Expresiín regular para encontrar títulos en mayusculas.\n",
    "    tituloMayusculas =re.compile(r'(I{1,3}|IV|V|VI{1,3}|IX|X)[-.)]+[A-Z -]+[:.\\n]') #[1-9]|\n",
    "    titulosMayusculasEncontrados = []\n",
    "\n",
    "    for m in tituloMayusculas.finditer(text):\n",
    "        titulosMayusculasEncontrados.append(m.group())\n",
    "\n",
    "    return titulosMayusculasEncontrados\n",
    "# titulosMAyuscula: lista que guarda los títulos en mayusculas\n",
    "titulosMayusculas=[]\n",
    "for expediente in dfLimpio:\n",
    "    titulosMayusculas.append(buscarTitulosMayusculas(expediente))\n",
    "\n",
    "dfTitulosMayusculasConStops = pd.DataFrame(titulosMayusculas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultima limpieza de titulos\n",
    "def limpiarTitulosHTML(text):\n",
    "    text = re.sub('[n]','',text)\n",
    "    text = re.sub('[\\\\\\]',' ',text)\n",
    "    return text\n",
    "titulosMayusculas = limpiarTitulosHTML(str(titulosMayusculas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de stopwords. Nueva limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "stops = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "# elimino stopwords\n",
    "def remove_stops(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Función que elimina stopwords\n",
    "    Params:\n",
    "        **texto**:texto a ser limpiado de stopwords\n",
    "\n",
    "    \"\"\"\n",
    "    texto = [\n",
    "        i for i in texto.split() if i not in stops\n",
    "    ]\n",
    "    return texto\n",
    "\n",
    "def limpiarTitulos(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n','',text)\n",
    "    text = re.sub(r'[a-z]\\.[a-z]\\.','',text)\n",
    "    text = re.sub(r'(i{2,3}|iv|vi{1,3}|ix)','',text)\n",
    "    text = re.sub(r'\\W',' ',text)    \n",
    "    text = re.sub(r'\\d+','',text)\n",
    "    text = re.sub(r' [a-z] ','',text)\n",
    "    \n",
    "    \n",
    "    return text\n",
    "\n",
    "# elimino stopwords y hago una última limpieza\n",
    "titulosMayusculasStop = limpiarTitulos(str(titulosMayusculas))\n",
    "titulosMayusculasStop = remove_stops(str(titulosMayusculasStop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASE DE ANALISIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRECUENCIA DE TOKENS\n",
    "# Metodo para contar la frecuencia de palabras de los tokens en titulos\n",
    "import pandas as pd\n",
    "dfTitulosMayusculas = pd.DataFrame(titulosMayusculasStop,columns=['tokens'])\n",
    "dfTitulosMayusculas.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medico             799\n",
      "puntos             538\n",
      "pericia            514\n",
      "conclusiones       496\n",
      "petitorio          454\n",
      "legales            451\n",
      "antecedentes       440\n",
      "consideraciones    384\n",
      "legal              310\n",
      "interes            282\n",
      "autos              280\n",
      "historia           275\n",
      "clinica            275\n",
      "examen             239\n",
      "actor              201\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Frecuencia de los tokens en los titulos.\n",
    "import pandas as pd\n",
    "FrecTitulosMayusculas = pd.DataFrame(titulosMayusculasStop)\n",
    "cantMay = FrecTitulosMayusculas.value_counts()\n",
    "print(cantMay[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe de tokens en titulos en mayusculas y sus frecuencias.\n",
    "import pandas as pd\n",
    "dfFrecTitulosMayusculas = pd.DataFrame(cantMay,columns=['frecuencia'])\n",
    "dfFrecTitulosMayusculas['frecuencia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METODO 1 - BIGRAMAS DE TITULOS EN MAYUSCULAS\n",
    "\n",
    "#bigrama de títulos con mayúsculas.\n",
    "bigramaMay=(list(nltk.ngrams(titulosMayusculasStop,2)))\n",
    "bigramaMay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un archivo csv para utilizar en la generacion de n-gramas\n",
    "\n",
    "#Se exporta el dataframe a un archivo csv\n",
    "dfTitulosMayusculas.to_csv('titTokenEnMayusculas.csv', index=False, sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METODO 2 - BIGRAMAS DE TITULOS EN MAYUSCULAS ---> RECOMENDADO\n",
    "\n",
    "# Creacion de bigramas de titulos en mayusculas\n",
    "f = open('titTokenEnMayusculas.csv')\n",
    "raw = f.read()\n",
    "\n",
    "token = nltk.word_tokenize(raw)\n",
    "\n",
    "bgsMayusculas = nltk.bigrams(token)\n",
    "\n",
    "bgsMayusculaFdist = nltk.FreqDist(bgsMayusculas)\n",
    "for k,v in bgsMayusculaFdist.items():\n",
    "    print(f'{k} {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('puntos', 'pericia'), 475),\n",
       " (('medico', 'legales'), 447),\n",
       " (('medico', 'legal'), 310),\n",
       " (('historia', 'clinica'), 272),\n",
       " (('consideraciones', 'medico'), 264),\n",
       " (('antecedentes', 'autos'), 246),\n",
       " (('interes', 'medico'), 244),\n",
       " (('autos', 'interes'), 193),\n",
       " (('pericia', 'conclusiones'), 191),\n",
       " (('contestacion', 'puntos'), 173),\n",
       " (('conclusiones', 'petitorio'), 155),\n",
       " (('hechos', 'historia'), 130),\n",
       " (('petitorio', 'antecedentes'), 126),\n",
       " (('legal', 'hechos'), 101),\n",
       " (('clinica', 'contestacion'), 101)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar los bigramas de mayor frecuencia\n",
    "bgsMayusculaFdist.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de dataframe de bigramas de titulos en mayusculas\n",
    "import pandas as pd\n",
    "bgsFrec=[]\n",
    "for k,v in bgsMayusculaFdist.items():\n",
    "    bgsFrec.append((k,v))\n",
    "\n",
    "dfBgsMayusculas = pd.DataFrame(bgsFrec,columns=['bigrama','frecuencia'])\n",
    "dfBgsMayusculas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METODO 1 - TRIGRAMAS DE TITULOS EN MAYUSCULAS\n",
    "\n",
    "#trigrama de títulos con mayúsculas.\n",
    "trigramaMay1=(list(nltk.ngrams(titulosMayusculasStop,3)))\n",
    "trigramaMay1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METODO 2 - TRIGRAMAS DE TITULOS EN MAYUSCULAS ---> RECOMENDADO\n",
    "\n",
    "# Creacion de trigramas de titulos en mayusculas\n",
    "f = open('titTokenEnMayusculas.csv')\n",
    "raw = f.read()\n",
    "\n",
    "token = nltk.word_tokenize(raw)\n",
    "\n",
    "trigsMayuscula = nltk.trigrams(token)\n",
    "\n",
    "trigsMayusculaFdist = nltk.FreqDist(trigsMayuscula)\n",
    "for k,v in trigsMayusculaFdist.items():\n",
    "    print(f'{k} {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('consideraciones', 'medico', 'legales'), 260),\n",
       " (('interes', 'medico', 'legal'), 218),\n",
       " (('antecedentes', 'autos', 'interes'), 183),\n",
       " (('puntos', 'pericia', 'conclusiones'), 183),\n",
       " (('autos', 'interes', 'medico'), 174),\n",
       " (('contestacion', 'puntos', 'pericia'), 165),\n",
       " (('hechos', 'historia', 'clinica'), 130),\n",
       " (('pericia', 'conclusiones', 'petitorio'), 120),\n",
       " (('medico', 'legal', 'hechos'), 101),\n",
       " (('historia', 'clinica', 'contestacion'), 101),\n",
       " (('clinica', 'contestacion', 'puntos'), 101),\n",
       " (('conclusiones', 'medico', 'legales'), 100),\n",
       " (('legal', 'hechos', 'historia'), 99),\n",
       " (('medico', 'legales', 'conclusiones'), 94),\n",
       " (('petitorio', 'antecedentes', 'autos'), 91)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar los trigramas de mayor frecuencia\n",
    "trigsMayusculaFdist.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de dataframe de trigramas de titulos en mayusculas\n",
    "import pandas as pd\n",
    "trigsFrec=[]\n",
    "for k,v in trigsMayusculaFdist.items():\n",
    "    trigsFrec.append((k,v))\n",
    "\n",
    "dfTrigsMayusculas = pd.DataFrame(trigsFrec,columns=['trigrama','frecuencia'])\n",
    "dfTrigsMayusculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f7c04c36d0b751253b9619efb75c537c6c26f8df6c81e91ba988c38192421cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
