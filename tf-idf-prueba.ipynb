{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizacion de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TOPIC MODELING\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = pd.read_csv(f)\n",
    "    return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stops(text, stops):\n",
    "    text = re.sub(r'(I{1,3}|IV|V|VI{1,3}|IX|X)[-.) ]+','',text)\n",
    "    text = re.sub(r'[^\\w\\s -]','',text)\n",
    "    text = re.sub(r'-',' ',text)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    final = []\n",
    "    for word in words:\n",
    "        if word not in stops:\n",
    "            final.append(word)\n",
    "    final = \" \".join(final)\n",
    "    final = final.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    final = \"\".join([i for i in final if not i.isdigit()])\n",
    "    while \"  \" in final:\n",
    "        final = final.replace(\"  \", \" \")\n",
    "    return (final)\n",
    "\n",
    "def clean_docs(docs):\n",
    "    stops = stopwords.words(\"spanish\")\n",
    "    final = []\n",
    "    for doc in docs:\n",
    "        clean_doc = remove_stops(doc, stops)\n",
    "        final.append(clean_doc)\n",
    "    return (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = load_data(\"titulosEncontrados.csv\")\n",
    "\n",
    "# print (descriptions[0])\n",
    "\n",
    "cleaned_docs = clean_docs(texto['titulo'])\n",
    "# print (cleaned_docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words(\"spanish\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "                                lowercase=False,\n",
    "                                use_idf=True,\n",
    "                                max_features=20000,\n",
    "                                max_df=0.99,\n",
    "                                min_df=50,\n",
    "                                ngram_range = (1,3),\n",
    "                                stop_words = stops\n",
    "                                \n",
    "\n",
    "                            )\n",
    "\n",
    "vectors = vectorizer.fit_transform(cleaned_docs)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "\n",
    "all_keywords = []\n",
    "\n",
    "for description in denselist:\n",
    "    x=0\n",
    "    keywords = []\n",
    "    for word in description:\n",
    "        if word > 0:\n",
    "            keywords.append(feature_names[x])\n",
    "        x=x+1\n",
    "    all_keywords.append(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  0.00000000e+00,  1.00000000e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  9.26062696e-01],\n",
       "       [ 1.00000000e+00,  1.00000000e+00, -2.22044605e-16, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         1.00000000e+00, -2.22044605e-16,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  9.26062696e-01,  1.00000000e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00, -2.22044605e-16]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 20\n",
    "\n",
    "model = KMeans(n_clusters=true_k, init=\"k-means++\", max_iter=100, n_init=1)\n",
    "\n",
    "model.fit(vectors)\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "with open (\"clusters_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(true_k):\n",
    "        f.write(f\"Cluster {i}\")\n",
    "        f.write(\"\\n\")\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            f.write (' %s' % terms[ind],)\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actor',\n",
       " 'actora',\n",
       " 'alicia',\n",
       " 'alicia victoria',\n",
       " 'analisis',\n",
       " 'antecedentes',\n",
       " 'antecedentes autos',\n",
       " 'antecedentes autos interes',\n",
       " 'antecedentes interes',\n",
       " 'art',\n",
       " 'autos',\n",
       " 'autos interes',\n",
       " 'autos interes medico',\n",
       " 'bibliografia',\n",
       " 'clinica',\n",
       " 'clinica actor',\n",
       " 'columna',\n",
       " 'complementarios',\n",
       " 'conclusiones',\n",
       " 'conclusiones medico',\n",
       " 'conclusiones medico legales',\n",
       " 'consideraciones',\n",
       " 'consideraciones medico',\n",
       " 'consideraciones medico legales',\n",
       " 'consideraciones medicolegales',\n",
       " 'contesta',\n",
       " 'contesta puntos',\n",
       " 'contesta puntos pericia',\n",
       " 'contestacion',\n",
       " 'contestacion puntos',\n",
       " 'contestacion puntos pericia',\n",
       " 'datos',\n",
       " 'datos personales',\n",
       " 'diagnostico',\n",
       " 'estudios',\n",
       " 'estudios complementarios',\n",
       " 'examen',\n",
       " 'examen actor',\n",
       " 'examen fisico',\n",
       " 'fisico',\n",
       " 'hechos',\n",
       " 'historia',\n",
       " 'historia clinica',\n",
       " 'historia clinica actor',\n",
       " 'identificacion',\n",
       " 'incapacidad',\n",
       " 'integral',\n",
       " 'integral problematica',\n",
       " 'interes',\n",
       " 'interes medico',\n",
       " 'interes medico legal',\n",
       " 'legal',\n",
       " 'legales',\n",
       " 'medica',\n",
       " 'medico',\n",
       " 'medico legal',\n",
       " 'medico legales',\n",
       " 'medicolegales',\n",
       " 'objeto',\n",
       " 'parte',\n",
       " 'pericia',\n",
       " 'periciales',\n",
       " 'perito',\n",
       " 'personales',\n",
       " 'petitorio',\n",
       " 'problematica',\n",
       " 'procedimientos',\n",
       " 'puntos',\n",
       " 'puntos pericia',\n",
       " 'puntos periciales',\n",
       " 'respuesta',\n",
       " 'respuesta puntos',\n",
       " 'respuesta puntos pericia',\n",
       " 'solicitados',\n",
       " 'tecnicas',\n",
       " 'victoria']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 75, 27, ..., 53, 54,  0],\n",
       "       [36,  0, 34, ..., 23, 22, 75],\n",
       "       [22, 23, 52, ..., 50, 51,  0],\n",
       "       ...,\n",
       "       [55, 51, 54, ..., 52, 53, 37],\n",
       "       [40,  5,  0, ..., 53, 54, 37],\n",
       "       [25, 27, 26, ..., 50, 51,  0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>actora</th>\n",
       "      <th>antecedentes</th>\n",
       "      <th>autos</th>\n",
       "      <th>clinica</th>\n",
       "      <th>complementarios</th>\n",
       "      <th>conclusiones</th>\n",
       "      <th>consideraciones</th>\n",
       "      <th>contestacion</th>\n",
       "      <th>datos</th>\n",
       "      <th>...</th>\n",
       "      <th>legal</th>\n",
       "      <th>legales</th>\n",
       "      <th>medico</th>\n",
       "      <th>medicolegales</th>\n",
       "      <th>parte</th>\n",
       "      <th>pericia</th>\n",
       "      <th>personales</th>\n",
       "      <th>petitorio</th>\n",
       "      <th>puntos</th>\n",
       "      <th>solicitados</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5771</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5772</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5776 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actor  actora  antecedentes  autos  clinica  complementarios  \\\n",
       "0         0       0             0      0        0                0   \n",
       "1         0       0             1      0        0                0   \n",
       "2         1       0             0      0        0                0   \n",
       "3         0       0             0      0        0                0   \n",
       "4         0       0             0      0        0                0   \n",
       "...     ...     ...           ...    ...      ...              ...   \n",
       "5771      0       0             0      0        0                0   \n",
       "5772      0       0             0      0        1                0   \n",
       "5773      0       0             0      0        0                0   \n",
       "5774      0       0             0      0        0                0   \n",
       "5775      0       0             0      0        0                0   \n",
       "\n",
       "      conclusiones  consideraciones  contestacion  datos  ...  legal  legales  \\\n",
       "0                0                0             0      0  ...      0        0   \n",
       "1                0                0             0      0  ...      1        0   \n",
       "2                0                0             0      0  ...      0        0   \n",
       "3                0                1             0      0  ...      0        1   \n",
       "4                1                0             0      0  ...      0        0   \n",
       "...            ...              ...           ...    ...  ...    ...      ...   \n",
       "5771             0                0             0      0  ...      0        0   \n",
       "5772             0                0             0      0  ...      0        0   \n",
       "5773             0                0             0      0  ...      0        0   \n",
       "5774             0                0             0      0  ...      0        0   \n",
       "5775             1                1             0      0  ...      0        1   \n",
       "\n",
       "      medico  medicolegales  parte  pericia  personales  petitorio  puntos  \\\n",
       "0          0              0      0        0           0          0       0   \n",
       "1          1              0      0        0           0          0       0   \n",
       "2          0              0      0        0           0          0       0   \n",
       "3          1              0      0        0           0          0       0   \n",
       "4          0              0      0        0           0          0       0   \n",
       "...      ...            ...    ...      ...         ...        ...     ...   \n",
       "5771       0              0      0        0           0          0       0   \n",
       "5772       0              0      0        0           0          0       0   \n",
       "5773       0              0      0        0           0          0       0   \n",
       "5774       0              0      0        0           0          0       1   \n",
       "5775       1              0      0        0           0          0       0   \n",
       "\n",
       "      solicitados  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "5771            0  \n",
       "5772            0  \n",
       "5773            1  \n",
       "5774            0  \n",
       "5775            0  \n",
       "\n",
       "[5776 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = load_data(\"titulosEncontrados.csv\")['titulo']\n",
    "coun_vect = CountVectorizer(max_features = 25)\n",
    "count_matrix = coun_vect.fit_transform(cleaned_docs)\n",
    "count_array = count_matrix.toarray()\n",
    "dfCountVec = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())\n",
    "dfCountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'antecedentes': 2, 'interes': 14, 'medico': 17, 'legal': 15, 'examen': 11, 'actor': 0, 'consideraciones': 7, 'legales': 16, 'conclusiones': 6, 'contestacion': 8, 'puntos': 23, 'pericia': 20, 'petitorio': 22, 'autos': 3, 'historia': 13, 'clinica': 4, 'estudios': 10, 'solicitados': 24, 'datos': 9, 'personales': 21, 'hechos': 12, 'complementarios': 5, 'actora': 1, 'medicolegales': 18, 'parte': 19}\n"
     ]
    }
   ],
   "source": [
    "print(coun_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actor', 'actora', 'antecedentes', 'autos', 'clinica', 'complementarios', 'conclusiones', 'consideraciones', 'contestacion', 'datos', 'estudios', 'examen', 'hechos', 'historia', 'interes', 'legal', 'legales', 'medico', 'medicolegales', 'parte', 'pericia', 'personales', 'petitorio', 'puntos', 'solicitados']\n"
     ]
    }
   ],
   "source": [
    "print(coun_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42875111758dffc1ca879dbe67063d4b14d2fb8b4b9c438105dae1201065df52"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
