{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorización de texto\n",
    "### Creación de los dataframe y limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "encontrados = pd.read_csv('titulosEncontrados.csv', sep=',',  encoding='utf-8')\n",
    "candidatos = pd.read_csv('titulosCandidatos.csv', sep=',',  encoding='utf-8')\n",
    "df_titulosCandidatos = pd.read_csv('df_titulosCandidatos.csv', sep=',',  encoding='utf-8')\n",
    "dfSinTitulosEncontrados = pd.read_csv('df_ExpSinTitulosEncontrados.csv', sep=',',  encoding='utf-8')\n",
    "dfUBicacionTitulosCandidatos = pd.read_csv('df_ubicacionTitulosCandidatos.csv', sep=',',  encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidatos = candidatos.fillna(value=' ')\n",
    "encontrados = encontrados.fillna(value=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10370, 25)\n",
      "(5286, 25)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.9, max_features=25,\n",
    "                                 min_df=100,\n",
    "                                 use_idf=True, ngram_range=(1,3))\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit(encontrados['titulo']) #fit the vectorizer to dfLimpio\n",
    "tfidf_matrix_transform_candidato = tfidf_vectorizer.transform(candidatos['titulo'])\n",
    "tfidf_matrix_transform_encontrado = tfidf_vectorizer.transform(encontrados['titulo'])\n",
    "print(tfidf_matrix_transform_candidato.shape)\n",
    "print(tfidf_matrix_transform_encontrado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['actor', 'antecedentes', 'antecedentes autos', 'autos', 'clinica',\n",
       "       'conclusiones', 'consideraciones', 'consideraciones medico',\n",
       "       'consideraciones medico legales', 'contestacion',\n",
       "       'contestacion puntos', 'examen', 'historia', 'historia clinica',\n",
       "       'interes', 'interes medico', 'legal', 'legales', 'medico',\n",
       "       'medico legal', 'medico legales', 'pericia', 'petitorio', 'puntos',\n",
       "       'puntos pericia'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = cosine_similarity(tfidf_matrix_transform_encontrado, tfidf_matrix_transform_candidato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.26513602 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.69446283 0.69446283 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.33347615 0.         0.         ... 0.         0.         0.43828479]]\n"
     ]
    }
   ],
   "source": [
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 10\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "km.fit(tfidf_matrix_transform_encontrado)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas de tfidf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# creamos el bag of words\n",
    "word2count = {}  \n",
    "for data in encontrados['titulo']:  \n",
    "    words = nltk.word_tokenize(data)  \n",
    "    for word in words:  \n",
    "        if word not in word2count.keys():  \n",
    "            word2count[word] = 1\n",
    "        else:  \n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidato = [w.split() for w in candidatos['titulo']]\n",
    "encontrado = [w.split() for w in encontrados['titulo']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('proyecto-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "009f8d941f1a5e5fa5c53bd1fe1f1a27e75894b84557fa679569ec42254b5e02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
